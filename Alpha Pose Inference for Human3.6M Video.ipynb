{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "continent-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cdflib\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import re\n",
    "import collections\n",
    "from torch._six import string_classes, int_classes\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "identical-provincial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Human3.6M Skeleton\n",
    "\n",
    "train_2d_file = '/media/ivan/Ivan/Project Lab/THESIS_FALL_DETECTION/2D to 3D Pose/3d_pose_baseline_pytorch/data/train_2d.pth.tar'\n",
    "train_3d_file = '/media/ivan/Ivan/Project Lab/THESIS_FALL_DETECTION/2D to 3D Pose/3d_pose_baseline_pytorch/data/train_3d.pth.tar'\n",
    "train_2d = torch.load(train_2d_file)\n",
    "train_3d = torch.load(train_3d_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "corresponding-virgin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([(1, 'Directions', 'Directions 1.54138969.h5'), (1, 'Directions', 'Directions 1.55011271.h5'), (1, 'Directions', 'Directions 1.58860488.h5'), (1, 'Directions', 'Directions 1.60457274.h5'), (1, 'Directions', 'Directions.54138969.h5'), (1, 'Directions', 'Directions.55011271.h5'), (1, 'Directions', 'Directions.58860488.h5'), (1, 'Directions', 'Directions.60457274.h5'), (1, 'Discussion', 'Discussion 1.54138969.h5'), (1, 'Discussion', 'Discussion 1.55011271.h5'), (1, 'Discussion', 'Discussion 1.58860488.h5'), (1, 'Discussion', 'Discussion 1.60457274.h5'), (1, 'Discussion', 'Discussion.54138969.h5'), (1, 'Discussion', 'Discussion.55011271.h5'), (1, 'Discussion', 'Discussion.58860488.h5'), (1, 'Discussion', 'Discussion.60457274.h5'), (1, 'Eating', 'Eating 2.54138969.h5'), (1, 'Eating', 'Eating 2.55011271.h5'), (1, 'Eating', 'Eating 2.58860488.h5'), (1, 'Eating', 'Eating 2.60457274.h5'), (1, 'Eating', 'Eating.54138969.h5'), (1, 'Eating', 'Eating.55011271.h5'), (1, 'Eating', 'Eating.58860488.h5'), (1, 'Eating', 'Eating.60457274.h5'), (1, 'Greeting', 'Greeting 1.54138969.h5'), (1, 'Greeting', 'Greeting 1.55011271.h5'), (1, 'Greeting', 'Greeting 1.58860488.h5'), (1, 'Greeting', 'Greeting 1.60457274.h5'), (1, 'Greeting', 'Greeting.54138969.h5'), (1, 'Greeting', 'Greeting.55011271.h5'), (1, 'Greeting', 'Greeting.58860488.h5'), (1, 'Greeting', 'Greeting.60457274.h5'), (1, 'Phoning', 'Phoning 1.54138969.h5'), (1, 'Phoning', 'Phoning 1.55011271.h5'), (1, 'Phoning', 'Phoning 1.58860488.h5'), (1, 'Phoning', 'Phoning 1.60457274.h5'), (1, 'Phoning', 'Phoning.54138969.h5'), (1, 'Phoning', 'Phoning.55011271.h5'), (1, 'Phoning', 'Phoning.58860488.h5'), (1, 'Phoning', 'Phoning.60457274.h5'), (1, 'Photo', 'Photo 1.54138969.h5'), (1, 'Photo', 'Photo 1.55011271.h5'), (1, 'Photo', 'Photo 1.58860488.h5'), (1, 'Photo', 'Photo 1.60457274.h5'), (1, 'Photo', 'Photo.54138969.h5'), (1, 'Photo', 'Photo.55011271.h5'), (1, 'Photo', 'Photo.58860488.h5'), (1, 'Photo', 'Photo.60457274.h5'), (1, 'Posing', 'Posing 1.54138969.h5'), (1, 'Posing', 'Posing 1.55011271.h5'), (1, 'Posing', 'Posing 1.58860488.h5'), (1, 'Posing', 'Posing 1.60457274.h5'), (1, 'Posing', 'Posing.54138969.h5'), (1, 'Posing', 'Posing.55011271.h5'), (1, 'Posing', 'Posing.58860488.h5'), (1, 'Posing', 'Posing.60457274.h5'), (1, 'Purchases', 'Purchases 1.54138969.h5'), (1, 'Purchases', 'Purchases 1.55011271.h5'), (1, 'Purchases', 'Purchases 1.58860488.h5'), (1, 'Purchases', 'Purchases 1.60457274.h5'), (1, 'Purchases', 'Purchases.54138969.h5'), (1, 'Purchases', 'Purchases.55011271.h5'), (1, 'Purchases', 'Purchases.58860488.h5'), (1, 'Purchases', 'Purchases.60457274.h5'), (1, 'Sitting', 'Sitting 1.54138969.h5'), (1, 'Sitting', 'Sitting 1.55011271.h5'), (1, 'Sitting', 'Sitting 1.58860488.h5'), (1, 'Sitting', 'Sitting 1.60457274.h5'), (1, 'Sitting', 'Sitting 2.54138969.h5'), (1, 'Sitting', 'Sitting 2.55011271.h5'), (1, 'Sitting', 'Sitting 2.58860488.h5'), (1, 'Sitting', 'Sitting 2.60457274.h5'), (1, 'SittingDown', 'SittingDown 2.54138969.h5'), (1, 'SittingDown', 'SittingDown 2.55011271.h5'), (1, 'SittingDown', 'SittingDown 2.58860488.h5'), (1, 'SittingDown', 'SittingDown 2.60457274.h5'), (1, 'SittingDown', 'SittingDown.54138969.h5'), (1, 'SittingDown', 'SittingDown.55011271.h5'), (1, 'SittingDown', 'SittingDown.58860488.h5'), (1, 'SittingDown', 'SittingDown.60457274.h5'), (1, 'Smoking', 'Smoking 1.54138969.h5'), (1, 'Smoking', 'Smoking 1.55011271.h5'), (1, 'Smoking', 'Smoking 1.58860488.h5'), (1, 'Smoking', 'Smoking 1.60457274.h5'), (1, 'Smoking', 'Smoking.54138969.h5'), (1, 'Smoking', 'Smoking.55011271.h5'), (1, 'Smoking', 'Smoking.58860488.h5'), (1, 'Smoking', 'Smoking.60457274.h5'), (1, 'Waiting', 'Waiting 1.54138969.h5'), (1, 'Waiting', 'Waiting 1.55011271.h5'), (1, 'Waiting', 'Waiting 1.58860488.h5'), (1, 'Waiting', 'Waiting 1.60457274.h5'), (1, 'Waiting', 'Waiting.54138969.h5'), (1, 'Waiting', 'Waiting.55011271.h5'), (1, 'Waiting', 'Waiting.58860488.h5'), (1, 'Waiting', 'Waiting.60457274.h5'), (1, 'WalkDog', 'WalkDog 1.54138969.h5'), (1, 'WalkDog', 'WalkDog 1.55011271.h5'), (1, 'WalkDog', 'WalkDog 1.58860488.h5'), (1, 'WalkDog', 'WalkDog 1.60457274.h5'), (1, 'WalkDog', 'WalkDog.54138969.h5'), (1, 'WalkDog', 'WalkDog.55011271.h5'), (1, 'WalkDog', 'WalkDog.58860488.h5'), (1, 'WalkDog', 'WalkDog.60457274.h5'), (1, 'WalkTogether', 'WalkTogether 1.54138969.h5'), (1, 'WalkTogether', 'WalkTogether 1.55011271.h5'), (1, 'WalkTogether', 'WalkTogether 1.58860488.h5'), (1, 'WalkTogether', 'WalkTogether 1.60457274.h5'), (1, 'WalkTogether', 'WalkTogether.54138969.h5'), (1, 'WalkTogether', 'WalkTogether.55011271.h5'), (1, 'WalkTogether', 'WalkTogether.58860488.h5'), (1, 'WalkTogether', 'WalkTogether.60457274.h5'), (1, 'Walking', 'Walking 1.54138969.h5'), (1, 'Walking', 'Walking 1.55011271.h5'), (1, 'Walking', 'Walking 1.58860488.h5'), (1, 'Walking', 'Walking 1.60457274.h5'), (1, 'Walking', 'Walking.54138969.h5'), (1, 'Walking', 'Walking.55011271.h5'), (1, 'Walking', 'Walking.58860488.h5'), (1, 'Walking', 'Walking.60457274.h5'), (5, 'Directions', 'Directions 1.54138969.h5'), (5, 'Directions', 'Directions 1.55011271.h5'), (5, 'Directions', 'Directions 1.58860488.h5'), (5, 'Directions', 'Directions 1.60457274.h5'), (5, 'Directions', 'Directions 2.54138969.h5'), (5, 'Directions', 'Directions 2.55011271.h5'), (5, 'Directions', 'Directions 2.58860488.h5'), (5, 'Directions', 'Directions 2.60457274.h5'), (5, 'Discussion', 'Discussion 2.54138969.h5'), (5, 'Discussion', 'Discussion 2.55011271.h5'), (5, 'Discussion', 'Discussion 2.58860488.h5'), (5, 'Discussion', 'Discussion 2.60457274.h5'), (5, 'Discussion', 'Discussion 3.54138969.h5'), (5, 'Discussion', 'Discussion 3.55011271.h5'), (5, 'Discussion', 'Discussion 3.58860488.h5'), (5, 'Discussion', 'Discussion 3.60457274.h5'), (5, 'Eating', 'Eating 1.54138969.h5'), (5, 'Eating', 'Eating 1.55011271.h5'), (5, 'Eating', 'Eating 1.58860488.h5'), (5, 'Eating', 'Eating 1.60457274.h5'), (5, 'Eating', 'Eating.54138969.h5'), (5, 'Eating', 'Eating.55011271.h5'), (5, 'Eating', 'Eating.58860488.h5'), (5, 'Eating', 'Eating.60457274.h5'), (5, 'Greeting', 'Greeting 1.54138969.h5'), (5, 'Greeting', 'Greeting 1.55011271.h5'), (5, 'Greeting', 'Greeting 1.58860488.h5'), (5, 'Greeting', 'Greeting 1.60457274.h5'), (5, 'Greeting', 'Greeting 2.54138969.h5'), (5, 'Greeting', 'Greeting 2.55011271.h5'), (5, 'Greeting', 'Greeting 2.58860488.h5'), (5, 'Greeting', 'Greeting 2.60457274.h5'), (5, 'Phoning', 'Phoning 1.54138969.h5'), (5, 'Phoning', 'Phoning 1.55011271.h5'), (5, 'Phoning', 'Phoning 1.58860488.h5'), (5, 'Phoning', 'Phoning 1.60457274.h5'), (5, 'Phoning', 'Phoning.54138969.h5'), (5, 'Phoning', 'Phoning.55011271.h5'), (5, 'Phoning', 'Phoning.58860488.h5'), (5, 'Phoning', 'Phoning.60457274.h5'), (5, 'Photo', 'Photo 2.54138969.h5'), (5, 'Photo', 'Photo 2.55011271.h5'), (5, 'Photo', 'Photo 2.58860488.h5'), (5, 'Photo', 'Photo 2.60457274.h5'), (5, 'Photo', 'Photo.54138969.h5'), (5, 'Photo', 'Photo.55011271.h5'), (5, 'Photo', 'Photo.58860488.h5'), (5, 'Photo', 'Photo.60457274.h5'), (5, 'Posing', 'Posing 1.54138969.h5'), (5, 'Posing', 'Posing 1.55011271.h5'), (5, 'Posing', 'Posing 1.58860488.h5'), (5, 'Posing', 'Posing 1.60457274.h5'), (5, 'Posing', 'Posing.54138969.h5'), (5, 'Posing', 'Posing.55011271.h5'), (5, 'Posing', 'Posing.58860488.h5'), (5, 'Posing', 'Posing.60457274.h5'), (5, 'Purchases', 'Purchases 1.54138969.h5'), (5, 'Purchases', 'Purchases 1.55011271.h5'), (5, 'Purchases', 'Purchases 1.58860488.h5'), (5, 'Purchases', 'Purchases 1.60457274.h5'), (5, 'Purchases', 'Purchases.54138969.h5'), (5, 'Purchases', 'Purchases.55011271.h5'), (5, 'Purchases', 'Purchases.58860488.h5'), (5, 'Purchases', 'Purchases.60457274.h5'), (5, 'Sitting', 'Sitting 1.54138969.h5'), (5, 'Sitting', 'Sitting 1.55011271.h5'), (5, 'Sitting', 'Sitting 1.58860488.h5'), (5, 'Sitting', 'Sitting 1.60457274.h5'), (5, 'Sitting', 'Sitting.54138969.h5'), (5, 'Sitting', 'Sitting.55011271.h5'), (5, 'Sitting', 'Sitting.58860488.h5'), (5, 'Sitting', 'Sitting.60457274.h5'), (5, 'SittingDown', 'SittingDown 1.54138969.h5'), (5, 'SittingDown', 'SittingDown 1.55011271.h5'), (5, 'SittingDown', 'SittingDown 1.58860488.h5'), (5, 'SittingDown', 'SittingDown 1.60457274.h5'), (5, 'SittingDown', 'SittingDown.54138969.h5'), (5, 'SittingDown', 'SittingDown.55011271.h5'), (5, 'SittingDown', 'SittingDown.58860488.h5'), (5, 'SittingDown', 'SittingDown.60457274.h5'), (5, 'Smoking', 'Smoking 1.54138969.h5'), (5, 'Smoking', 'Smoking 1.55011271.h5'), (5, 'Smoking', 'Smoking 1.58860488.h5'), (5, 'Smoking', 'Smoking 1.60457274.h5'), (5, 'Smoking', 'Smoking.54138969.h5'), (5, 'Smoking', 'Smoking.55011271.h5'), (5, 'Smoking', 'Smoking.58860488.h5'), (5, 'Smoking', 'Smoking.60457274.h5'), (5, 'Waiting', 'Waiting 1.54138969.h5'), (5, 'Waiting', 'Waiting 1.55011271.h5'), (5, 'Waiting', 'Waiting 1.58860488.h5'), (5, 'Waiting', 'Waiting 1.60457274.h5'), (5, 'Waiting', 'Waiting 2.54138969.h5'), (5, 'Waiting', 'Waiting 2.55011271.h5'), (5, 'Waiting', 'Waiting 2.58860488.h5'), (5, 'Waiting', 'Waiting 2.60457274.h5'), (5, 'WalkDog', 'WalkDog 1.54138969.h5'), (5, 'WalkDog', 'WalkDog 1.55011271.h5'), (5, 'WalkDog', 'WalkDog 1.58860488.h5'), (5, 'WalkDog', 'WalkDog 1.60457274.h5'), (5, 'WalkDog', 'WalkDog.54138969.h5'), (5, 'WalkDog', 'WalkDog.55011271.h5'), (5, 'WalkDog', 'WalkDog.58860488.h5'), (5, 'WalkDog', 'WalkDog.60457274.h5'), (5, 'WalkTogether', 'WalkTogether 1.54138969.h5'), (5, 'WalkTogether', 'WalkTogether 1.55011271.h5'), (5, 'WalkTogether', 'WalkTogether 1.58860488.h5'), (5, 'WalkTogether', 'WalkTogether 1.60457274.h5'), (5, 'WalkTogether', 'WalkTogether.54138969.h5'), (5, 'WalkTogether', 'WalkTogether.55011271.h5'), (5, 'WalkTogether', 'WalkTogether.58860488.h5'), (5, 'WalkTogether', 'WalkTogether.60457274.h5'), (5, 'Walking', 'Walking 1.54138969.h5'), (5, 'Walking', 'Walking 1.55011271.h5'), (5, 'Walking', 'Walking 1.58860488.h5'), (5, 'Walking', 'Walking 1.60457274.h5'), (5, 'Walking', 'Walking.54138969.h5'), (5, 'Walking', 'Walking.55011271.h5'), (5, 'Walking', 'Walking.58860488.h5'), (5, 'Walking', 'Walking.60457274.h5'), (6, 'Directions', 'Directions 1.54138969.h5'), (6, 'Directions', 'Directions 1.55011271.h5'), (6, 'Directions', 'Directions 1.58860488.h5'), (6, 'Directions', 'Directions 1.60457274.h5'), (6, 'Directions', 'Directions.54138969.h5'), (6, 'Directions', 'Directions.55011271.h5'), (6, 'Directions', 'Directions.58860488.h5'), (6, 'Directions', 'Directions.60457274.h5'), (6, 'Discussion', 'Discussion 1.54138969.h5'), (6, 'Discussion', 'Discussion 1.55011271.h5'), (6, 'Discussion', 'Discussion 1.58860488.h5'), (6, 'Discussion', 'Discussion 1.60457274.h5'), (6, 'Discussion', 'Discussion.54138969.h5'), (6, 'Discussion', 'Discussion.55011271.h5'), (6, 'Discussion', 'Discussion.58860488.h5'), (6, 'Discussion', 'Discussion.60457274.h5'), (6, 'Eating', 'Eating 1.54138969.h5'), (6, 'Eating', 'Eating 1.55011271.h5'), (6, 'Eating', 'Eating 1.58860488.h5'), (6, 'Eating', 'Eating 1.60457274.h5'), (6, 'Eating', 'Eating 2.54138969.h5'), (6, 'Eating', 'Eating 2.55011271.h5'), (6, 'Eating', 'Eating 2.58860488.h5'), (6, 'Eating', 'Eating 2.60457274.h5'), (6, 'Greeting', 'Greeting 1.54138969.h5'), (6, 'Greeting', 'Greeting 1.55011271.h5'), (6, 'Greeting', 'Greeting 1.58860488.h5'), (6, 'Greeting', 'Greeting 1.60457274.h5'), (6, 'Greeting', 'Greeting.54138969.h5'), (6, 'Greeting', 'Greeting.55011271.h5'), (6, 'Greeting', 'Greeting.58860488.h5'), (6, 'Greeting', 'Greeting.60457274.h5'), (6, 'Phoning', 'Phoning 1.54138969.h5'), (6, 'Phoning', 'Phoning 1.55011271.h5'), (6, 'Phoning', 'Phoning 1.58860488.h5'), (6, 'Phoning', 'Phoning 1.60457274.h5'), (6, 'Phoning', 'Phoning.54138969.h5'), (6, 'Phoning', 'Phoning.55011271.h5'), (6, 'Phoning', 'Phoning.58860488.h5'), (6, 'Phoning', 'Phoning.60457274.h5'), (6, 'Photo', 'Photo 1.54138969.h5'), (6, 'Photo', 'Photo 1.55011271.h5'), (6, 'Photo', 'Photo 1.58860488.h5'), (6, 'Photo', 'Photo 1.60457274.h5'), (6, 'Photo', 'Photo.54138969.h5'), (6, 'Photo', 'Photo.55011271.h5'), (6, 'Photo', 'Photo.58860488.h5'), (6, 'Photo', 'Photo.60457274.h5'), (6, 'Posing', 'Posing 2.54138969.h5'), (6, 'Posing', 'Posing 2.55011271.h5'), (6, 'Posing', 'Posing 2.58860488.h5'), (6, 'Posing', 'Posing 2.60457274.h5'), (6, 'Posing', 'Posing.54138969.h5'), (6, 'Posing', 'Posing.55011271.h5'), (6, 'Posing', 'Posing.58860488.h5'), (6, 'Posing', 'Posing.60457274.h5'), (6, 'Purchases', 'Purchases 1.54138969.h5'), (6, 'Purchases', 'Purchases 1.55011271.h5'), (6, 'Purchases', 'Purchases 1.58860488.h5'), (6, 'Purchases', 'Purchases 1.60457274.h5'), (6, 'Purchases', 'Purchases.54138969.h5'), (6, 'Purchases', 'Purchases.55011271.h5'), (6, 'Purchases', 'Purchases.58860488.h5'), (6, 'Purchases', 'Purchases.60457274.h5'), (6, 'Sitting', 'Sitting 1.54138969.h5'), (6, 'Sitting', 'Sitting 1.55011271.h5'), (6, 'Sitting', 'Sitting 1.58860488.h5'), (6, 'Sitting', 'Sitting 1.60457274.h5'), (6, 'Sitting', 'Sitting 2.54138969.h5'), (6, 'Sitting', 'Sitting 2.55011271.h5'), (6, 'Sitting', 'Sitting 2.58860488.h5'), (6, 'Sitting', 'Sitting 2.60457274.h5'), (6, 'SittingDown', 'SittingDown 1.54138969.h5'), (6, 'SittingDown', 'SittingDown 1.55011271.h5'), (6, 'SittingDown', 'SittingDown 1.58860488.h5'), (6, 'SittingDown', 'SittingDown 1.60457274.h5'), (6, 'SittingDown', 'SittingDown.54138969.h5'), (6, 'SittingDown', 'SittingDown.55011271.h5'), (6, 'SittingDown', 'SittingDown.58860488.h5'), (6, 'SittingDown', 'SittingDown.60457274.h5'), (6, 'Smoking', 'Smoking 1.54138969.h5'), (6, 'Smoking', 'Smoking 1.55011271.h5'), (6, 'Smoking', 'Smoking 1.58860488.h5'), (6, 'Smoking', 'Smoking 1.60457274.h5'), (6, 'Smoking', 'Smoking.54138969.h5'), (6, 'Smoking', 'Smoking.55011271.h5'), (6, 'Smoking', 'Smoking.58860488.h5'), (6, 'Smoking', 'Smoking.60457274.h5'), (6, 'Waiting', 'Waiting 3.54138969.h5'), (6, 'Waiting', 'Waiting 3.55011271.h5'), (6, 'Waiting', 'Waiting 3.58860488.h5'), (6, 'Waiting', 'Waiting 3.60457274.h5'), (6, 'Waiting', 'Waiting.54138969.h5'), (6, 'Waiting', 'Waiting.55011271.h5'), (6, 'Waiting', 'Waiting.58860488.h5'), (6, 'Waiting', 'Waiting.60457274.h5'), (6, 'WalkDog', 'WalkDog 1.54138969.h5'), (6, 'WalkDog', 'WalkDog 1.55011271.h5'), (6, 'WalkDog', 'WalkDog 1.58860488.h5'), (6, 'WalkDog', 'WalkDog 1.60457274.h5'), (6, 'WalkDog', 'WalkDog.54138969.h5'), (6, 'WalkDog', 'WalkDog.55011271.h5'), (6, 'WalkDog', 'WalkDog.58860488.h5'), (6, 'WalkDog', 'WalkDog.60457274.h5'), (6, 'WalkTogether', 'WalkTogether 1.54138969.h5'), (6, 'WalkTogether', 'WalkTogether 1.55011271.h5'), (6, 'WalkTogether', 'WalkTogether 1.58860488.h5'), (6, 'WalkTogether', 'WalkTogether 1.60457274.h5'), (6, 'WalkTogether', 'WalkTogether.54138969.h5'), (6, 'WalkTogether', 'WalkTogether.55011271.h5'), (6, 'WalkTogether', 'WalkTogether.58860488.h5'), (6, 'WalkTogether', 'WalkTogether.60457274.h5'), (6, 'Walking', 'Walking 1.54138969.h5'), (6, 'Walking', 'Walking 1.55011271.h5'), (6, 'Walking', 'Walking 1.58860488.h5'), (6, 'Walking', 'Walking 1.60457274.h5'), (6, 'Walking', 'Walking.54138969.h5'), (6, 'Walking', 'Walking.55011271.h5'), (6, 'Walking', 'Walking.58860488.h5'), (6, 'Walking', 'Walking.60457274.h5'), (7, 'Directions', 'Directions 1.54138969.h5'), (7, 'Directions', 'Directions 1.55011271.h5'), (7, 'Directions', 'Directions 1.58860488.h5'), (7, 'Directions', 'Directions 1.60457274.h5'), (7, 'Directions', 'Directions.54138969.h5'), (7, 'Directions', 'Directions.55011271.h5'), (7, 'Directions', 'Directions.58860488.h5'), (7, 'Directions', 'Directions.60457274.h5'), (7, 'Discussion', 'Discussion 1.54138969.h5'), (7, 'Discussion', 'Discussion 1.55011271.h5'), (7, 'Discussion', 'Discussion 1.58860488.h5'), (7, 'Discussion', 'Discussion 1.60457274.h5'), (7, 'Discussion', 'Discussion.54138969.h5'), (7, 'Discussion', 'Discussion.55011271.h5'), (7, 'Discussion', 'Discussion.58860488.h5'), (7, 'Discussion', 'Discussion.60457274.h5'), (7, 'Eating', 'Eating 1.54138969.h5'), (7, 'Eating', 'Eating 1.55011271.h5'), (7, 'Eating', 'Eating 1.58860488.h5'), (7, 'Eating', 'Eating 1.60457274.h5'), (7, 'Eating', 'Eating.54138969.h5'), (7, 'Eating', 'Eating.55011271.h5'), (7, 'Eating', 'Eating.58860488.h5'), (7, 'Eating', 'Eating.60457274.h5'), (7, 'Greeting', 'Greeting 1.54138969.h5'), (7, 'Greeting', 'Greeting 1.55011271.h5'), (7, 'Greeting', 'Greeting 1.58860488.h5'), (7, 'Greeting', 'Greeting 1.60457274.h5'), (7, 'Greeting', 'Greeting.54138969.h5'), (7, 'Greeting', 'Greeting.55011271.h5'), (7, 'Greeting', 'Greeting.58860488.h5'), (7, 'Greeting', 'Greeting.60457274.h5'), (7, 'Phoning', 'Phoning 2.54138969.h5'), (7, 'Phoning', 'Phoning 2.55011271.h5'), (7, 'Phoning', 'Phoning 2.58860488.h5'), (7, 'Phoning', 'Phoning 2.60457274.h5'), (7, 'Phoning', 'Phoning.54138969.h5'), (7, 'Phoning', 'Phoning.55011271.h5'), (7, 'Phoning', 'Phoning.58860488.h5'), (7, 'Phoning', 'Phoning.60457274.h5'), (7, 'Photo', 'Photo 1.54138969.h5'), (7, 'Photo', 'Photo 1.55011271.h5'), (7, 'Photo', 'Photo 1.58860488.h5'), (7, 'Photo', 'Photo 1.60457274.h5'), (7, 'Photo', 'Photo.54138969.h5'), (7, 'Photo', 'Photo.55011271.h5'), (7, 'Photo', 'Photo.58860488.h5'), (7, 'Photo', 'Photo.60457274.h5'), (7, 'Posing', 'Posing 1.54138969.h5'), (7, 'Posing', 'Posing 1.55011271.h5'), (7, 'Posing', 'Posing 1.58860488.h5'), (7, 'Posing', 'Posing 1.60457274.h5'), (7, 'Posing', 'Posing.54138969.h5'), (7, 'Posing', 'Posing.55011271.h5'), (7, 'Posing', 'Posing.58860488.h5'), (7, 'Posing', 'Posing.60457274.h5'), (7, 'Purchases', 'Purchases 1.54138969.h5'), (7, 'Purchases', 'Purchases 1.55011271.h5'), (7, 'Purchases', 'Purchases 1.58860488.h5'), (7, 'Purchases', 'Purchases 1.60457274.h5'), (7, 'Purchases', 'Purchases.54138969.h5'), (7, 'Purchases', 'Purchases.55011271.h5'), (7, 'Purchases', 'Purchases.58860488.h5'), (7, 'Purchases', 'Purchases.60457274.h5'), (7, 'Sitting', 'Sitting 1.54138969.h5'), (7, 'Sitting', 'Sitting 1.55011271.h5'), (7, 'Sitting', 'Sitting 1.58860488.h5'), (7, 'Sitting', 'Sitting 1.60457274.h5'), (7, 'Sitting', 'Sitting.54138969.h5'), (7, 'Sitting', 'Sitting.55011271.h5'), (7, 'Sitting', 'Sitting.58860488.h5'), (7, 'Sitting', 'Sitting.60457274.h5'), (7, 'SittingDown', 'SittingDown 1.54138969.h5'), (7, 'SittingDown', 'SittingDown 1.55011271.h5'), (7, 'SittingDown', 'SittingDown 1.58860488.h5'), (7, 'SittingDown', 'SittingDown 1.60457274.h5'), (7, 'SittingDown', 'SittingDown.54138969.h5'), (7, 'SittingDown', 'SittingDown.55011271.h5'), (7, 'SittingDown', 'SittingDown.58860488.h5'), (7, 'SittingDown', 'SittingDown.60457274.h5'), (7, 'Smoking', 'Smoking 1.54138969.h5'), (7, 'Smoking', 'Smoking 1.55011271.h5'), (7, 'Smoking', 'Smoking 1.58860488.h5'), (7, 'Smoking', 'Smoking 1.60457274.h5'), (7, 'Smoking', 'Smoking.54138969.h5'), (7, 'Smoking', 'Smoking.55011271.h5'), (7, 'Smoking', 'Smoking.58860488.h5'), (7, 'Smoking', 'Smoking.60457274.h5'), (7, 'Waiting', 'Waiting 1.54138969.h5'), (7, 'Waiting', 'Waiting 1.55011271.h5'), (7, 'Waiting', 'Waiting 1.58860488.h5'), (7, 'Waiting', 'Waiting 1.60457274.h5'), (7, 'Waiting', 'Waiting 2.54138969.h5'), (7, 'Waiting', 'Waiting 2.55011271.h5'), (7, 'Waiting', 'Waiting 2.58860488.h5'), (7, 'Waiting', 'Waiting 2.60457274.h5'), (7, 'WalkDog', 'WalkDog 1.54138969.h5'), (7, 'WalkDog', 'WalkDog 1.55011271.h5'), (7, 'WalkDog', 'WalkDog 1.58860488.h5'), (7, 'WalkDog', 'WalkDog 1.60457274.h5'), (7, 'WalkDog', 'WalkDog.54138969.h5'), (7, 'WalkDog', 'WalkDog.55011271.h5'), (7, 'WalkDog', 'WalkDog.58860488.h5'), (7, 'WalkDog', 'WalkDog.60457274.h5'), (7, 'WalkTogether', 'WalkTogether 1.54138969.h5'), (7, 'WalkTogether', 'WalkTogether 1.55011271.h5'), (7, 'WalkTogether', 'WalkTogether 1.58860488.h5'), (7, 'WalkTogether', 'WalkTogether 1.60457274.h5'), (7, 'WalkTogether', 'WalkTogether.54138969.h5'), (7, 'WalkTogether', 'WalkTogether.55011271.h5'), (7, 'WalkTogether', 'WalkTogether.58860488.h5'), (7, 'WalkTogether', 'WalkTogether.60457274.h5'), (7, 'Walking', 'Walking 1.54138969.h5'), (7, 'Walking', 'Walking 1.55011271.h5'), (7, 'Walking', 'Walking 1.58860488.h5'), (7, 'Walking', 'Walking 1.60457274.h5'), (7, 'Walking', 'Walking 2.54138969.h5'), (7, 'Walking', 'Walking 2.55011271.h5'), (7, 'Walking', 'Walking 2.58860488.h5'), (7, 'Walking', 'Walking 2.60457274.h5'), (8, 'Directions', 'Directions 1.54138969.h5'), (8, 'Directions', 'Directions 1.55011271.h5'), (8, 'Directions', 'Directions 1.58860488.h5'), (8, 'Directions', 'Directions 1.60457274.h5'), (8, 'Directions', 'Directions.54138969.h5'), (8, 'Directions', 'Directions.55011271.h5'), (8, 'Directions', 'Directions.58860488.h5'), (8, 'Directions', 'Directions.60457274.h5'), (8, 'Discussion', 'Discussion 1.54138969.h5'), (8, 'Discussion', 'Discussion 1.55011271.h5'), (8, 'Discussion', 'Discussion 1.58860488.h5'), (8, 'Discussion', 'Discussion 1.60457274.h5'), (8, 'Discussion', 'Discussion.54138969.h5'), (8, 'Discussion', 'Discussion.55011271.h5'), (8, 'Discussion', 'Discussion.58860488.h5'), (8, 'Discussion', 'Discussion.60457274.h5'), (8, 'Eating', 'Eating 1.54138969.h5'), (8, 'Eating', 'Eating 1.55011271.h5'), (8, 'Eating', 'Eating 1.58860488.h5'), (8, 'Eating', 'Eating 1.60457274.h5'), (8, 'Eating', 'Eating.54138969.h5'), (8, 'Eating', 'Eating.55011271.h5'), (8, 'Eating', 'Eating.58860488.h5'), (8, 'Eating', 'Eating.60457274.h5'), (8, 'Greeting', 'Greeting 1.54138969.h5'), (8, 'Greeting', 'Greeting 1.55011271.h5'), (8, 'Greeting', 'Greeting 1.58860488.h5'), (8, 'Greeting', 'Greeting 1.60457274.h5'), (8, 'Greeting', 'Greeting.54138969.h5'), (8, 'Greeting', 'Greeting.55011271.h5'), (8, 'Greeting', 'Greeting.58860488.h5'), (8, 'Greeting', 'Greeting.60457274.h5'), (8, 'Phoning', 'Phoning 1.54138969.h5'), (8, 'Phoning', 'Phoning 1.55011271.h5'), (8, 'Phoning', 'Phoning 1.58860488.h5'), (8, 'Phoning', 'Phoning 1.60457274.h5'), (8, 'Phoning', 'Phoning.54138969.h5'), (8, 'Phoning', 'Phoning.55011271.h5'), (8, 'Phoning', 'Phoning.58860488.h5'), (8, 'Phoning', 'Phoning.60457274.h5'), (8, 'Photo', 'Photo 1.54138969.h5'), (8, 'Photo', 'Photo 1.55011271.h5'), (8, 'Photo', 'Photo 1.58860488.h5'), (8, 'Photo', 'Photo 1.60457274.h5'), (8, 'Photo', 'Photo.54138969.h5'), (8, 'Photo', 'Photo.55011271.h5'), (8, 'Photo', 'Photo.58860488.h5'), (8, 'Photo', 'Photo.60457274.h5'), (8, 'Posing', 'Posing 1.54138969.h5'), (8, 'Posing', 'Posing 1.55011271.h5'), (8, 'Posing', 'Posing 1.58860488.h5'), (8, 'Posing', 'Posing 1.60457274.h5'), (8, 'Posing', 'Posing.54138969.h5'), (8, 'Posing', 'Posing.55011271.h5'), (8, 'Posing', 'Posing.58860488.h5'), (8, 'Posing', 'Posing.60457274.h5'), (8, 'Purchases', 'Purchases 1.54138969.h5'), (8, 'Purchases', 'Purchases 1.55011271.h5'), (8, 'Purchases', 'Purchases 1.58860488.h5'), (8, 'Purchases', 'Purchases 1.60457274.h5'), (8, 'Purchases', 'Purchases.54138969.h5'), (8, 'Purchases', 'Purchases.55011271.h5'), (8, 'Purchases', 'Purchases.58860488.h5'), (8, 'Purchases', 'Purchases.60457274.h5'), (8, 'Sitting', 'Sitting 1.54138969.h5'), (8, 'Sitting', 'Sitting 1.55011271.h5'), (8, 'Sitting', 'Sitting 1.58860488.h5'), (8, 'Sitting', 'Sitting 1.60457274.h5'), (8, 'Sitting', 'Sitting.54138969.h5'), (8, 'Sitting', 'Sitting.55011271.h5'), (8, 'Sitting', 'Sitting.58860488.h5'), (8, 'Sitting', 'Sitting.60457274.h5'), (8, 'SittingDown', 'SittingDown 1.54138969.h5'), (8, 'SittingDown', 'SittingDown 1.55011271.h5'), (8, 'SittingDown', 'SittingDown 1.58860488.h5'), (8, 'SittingDown', 'SittingDown 1.60457274.h5'), (8, 'SittingDown', 'SittingDown.54138969.h5'), (8, 'SittingDown', 'SittingDown.55011271.h5'), (8, 'SittingDown', 'SittingDown.58860488.h5'), (8, 'SittingDown', 'SittingDown.60457274.h5'), (8, 'Smoking', 'Smoking 1.54138969.h5'), (8, 'Smoking', 'Smoking 1.55011271.h5'), (8, 'Smoking', 'Smoking 1.58860488.h5'), (8, 'Smoking', 'Smoking 1.60457274.h5'), (8, 'Smoking', 'Smoking.54138969.h5'), (8, 'Smoking', 'Smoking.55011271.h5'), (8, 'Smoking', 'Smoking.58860488.h5'), (8, 'Smoking', 'Smoking.60457274.h5'), (8, 'Waiting', 'Waiting 1.54138969.h5'), (8, 'Waiting', 'Waiting 1.55011271.h5'), (8, 'Waiting', 'Waiting 1.58860488.h5'), (8, 'Waiting', 'Waiting 1.60457274.h5'), (8, 'Waiting', 'Waiting.54138969.h5'), (8, 'Waiting', 'Waiting.55011271.h5'), (8, 'Waiting', 'Waiting.58860488.h5'), (8, 'Waiting', 'Waiting.60457274.h5'), (8, 'WalkDog', 'WalkDog 1.54138969.h5'), (8, 'WalkDog', 'WalkDog 1.55011271.h5'), (8, 'WalkDog', 'WalkDog 1.58860488.h5'), (8, 'WalkDog', 'WalkDog 1.60457274.h5'), (8, 'WalkDog', 'WalkDog.54138969.h5'), (8, 'WalkDog', 'WalkDog.55011271.h5'), (8, 'WalkDog', 'WalkDog.58860488.h5'), (8, 'WalkDog', 'WalkDog.60457274.h5'), (8, 'WalkTogether', 'WalkTogether 1.54138969.h5'), (8, 'WalkTogether', 'WalkTogether 1.55011271.h5'), (8, 'WalkTogether', 'WalkTogether 1.58860488.h5'), (8, 'WalkTogether', 'WalkTogether 1.60457274.h5'), (8, 'WalkTogether', 'WalkTogether 2.54138969.h5'), (8, 'WalkTogether', 'WalkTogether 2.55011271.h5'), (8, 'WalkTogether', 'WalkTogether 2.58860488.h5'), (8, 'WalkTogether', 'WalkTogether 2.60457274.h5'), (8, 'Walking', 'Walking 1.54138969.h5'), (8, 'Walking', 'Walking 1.55011271.h5'), (8, 'Walking', 'Walking 1.58860488.h5'), (8, 'Walking', 'Walking 1.60457274.h5'), (8, 'Walking', 'Walking.54138969.h5'), (8, 'Walking', 'Walking.55011271.h5'), (8, 'Walking', 'Walking.58860488.h5'), (8, 'Walking', 'Walking.60457274.h5')])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_2d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "knowing-label",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1383, 32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_2d[(1, 'Directions', 'Directions 1.54138969.h5')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "accepted-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename Unconsistent Filename\n",
    "\n",
    "for key in train_2d.keys():\n",
    "#     print(key)\n",
    "    filename = os.path.splitext(key[2])[0]\n",
    "    videopath = \"../2D to 3D Pose/Dataset/Human3.6m/Videos/S\"+str(key[0])+\"/Videos/\"\n",
    "    for file in os.listdir(videopath):\n",
    "#         print(file)\n",
    "        if file.endswith(\".mp4\"):\n",
    "            if file.find(\"TakingPhoto\")>-1:\n",
    "                print(\"Rename taking photo\")\n",
    "                os.rename(os.path.join(videopath, file), os.path.join(videopath, file.replace(\"TakingPhoto\", \"Photo\")))\n",
    "            if file.find(\"WalkingDog\")>-1:\n",
    "                print(\"Rename Walking Dog\")\n",
    "                os.rename(os.path.join(videopath, file), os.path.join(videopath, file.replace(\"WalkingDog\", \"WalkDog\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-paint",
   "metadata": {},
   "source": [
    "# Alpha Pose Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "pregnant-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_alphapose={\n",
    "    # Use 17 skeleton point\n",
    "    \"Nose\": 0,\n",
    "    #\"Neck\": \"-\",\n",
    "    \"RShoulder\": 6,\n",
    "    \"RElbow\": 8,\n",
    "    \"RWrist\": 10,\n",
    "    \"LShoulder\": 5,\n",
    "    \"LElbow\": 7,\n",
    "    \"LWrist\": 9,\n",
    "    \"RHip\": 12,\n",
    "    \"RKnee\": 14,\n",
    "    \"RAnkle\": 16,\n",
    "    \"LHip\": 11,\n",
    "    \"LKnee\": 13,\n",
    "    \"LAnkle\": 15,\n",
    "    \"REye\": 2,\n",
    "    \"LEye\": 1,\n",
    "    \"REar\": 4,\n",
    "    \"LEar\": 3\n",
    "}\n",
    "\n",
    "\n",
    "def data_converter(data):\n",
    "    data=data['keypoints']\n",
    "    keypoints=[]\n",
    "    kp_score=[]\n",
    "    for a in range (0,len(data)):\n",
    "        score=[]\n",
    "        if ((a+3)%3==0):\n",
    "            keypoints.append(data[a])\n",
    "            keypoints.append(data[a+1])\n",
    "        elif((a+1)%3==0):\n",
    "            score=[data[a]]\n",
    "            kp_score.append(score)\n",
    "\n",
    "    return keypoints\n",
    "    \n",
    "    \n",
    "def euclidean_dist(a, b):\n",
    "    # This function calculates the euclidean distance between 2 point in 2-D coordinates\n",
    "    # if one of two points is (0,0), dist = 0\n",
    "    # a, b: input array with dimension: m, 2\n",
    "    # m: number of samples\n",
    "    # 2: x and y coordinate\n",
    "    try:\n",
    "        if (a.shape[1] == 2 and a.shape == b.shape):\n",
    "            # check if element of a and b is (0,0)\n",
    "            bol_a = (a[:,0] != 0).astype(int)\n",
    "            bol_b = (b[:,0] != 0).astype(int)\n",
    "            dist = np.linalg.norm(a-b, axis=1)\n",
    "            return((dist*bol_a*bol_b).reshape(a.shape[0],1))\n",
    "    except:\n",
    "        print(\"[Error]: Check dimension of input vector\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "# Function to find next in alpha pose because alpha pose did not have neck\n",
    "\n",
    "def find_neck(alpha_example):\n",
    "    \n",
    "    # 10 and 11 is x and y coordinate for left shoulder of alpha pose\n",
    "    x1= alpha_example[:,10] \n",
    "    y1= alpha_example[:,11]\n",
    "    \n",
    "    \n",
    "    # 12 and 13 is x and y coordinate for right shoulder of alpha pose\n",
    "    x2= alpha_example[:,12]\n",
    "    y2= alpha_example[:,13]\n",
    "    \n",
    "    # Result will be  neck coordinate(array([586.35131836, 472.55082703]), array([559.9307251 , 480.63751221])) ((x1,x2),(y1,y2))\n",
    "    neck_= ((x1 + x2)/2, (y1 + y2)/2)\n",
    "    \n",
    "    result_neck=[]\n",
    "    for a,b in zip(neck_[0],neck_[1]):\n",
    "        result_neck.append([a,b])\n",
    "    \n",
    "    neck=np.asarray(result_neck)\n",
    "    return neck\n",
    "\n",
    "def norm_alpha(X):\n",
    "    num_sample = X.shape[0]\n",
    "    # Keypoints\n",
    "    Nose = X[:,index_alphapose['Nose']*2:index_alphapose['Nose']*2+2]\n",
    "    Neck = find_neck(X)\n",
    "    RShoulder = X[:,index_alphapose['RShoulder']*2:index_alphapose['RShoulder']*2+2]\n",
    "    RElbow = X[:,index_alphapose['RElbow']*2:index_alphapose['RElbow']*2+2]\n",
    "    RWrist = X[:,index_alphapose['RWrist']*2:index_alphapose['RWrist']*2+2]\n",
    "    LShoulder = X[:,index_alphapose['LShoulder']*2:index_alphapose['LShoulder']*2+2]\n",
    "    LElbow = X[:,index_alphapose['LElbow']*2:index_alphapose['LElbow']*2+2]\n",
    "    LWrist = X[:,index_alphapose['LWrist']*2:index_alphapose['LWrist']*2+2]\n",
    "    RHip = X[:,index_alphapose['RHip']*2:index_alphapose['RHip']*2+2]\n",
    "    RKnee = X[:,index_alphapose['RKnee']*2:index_alphapose['RKnee']*2+2]\n",
    "    RAnkle = X[:,index_alphapose['RAnkle']*2:index_alphapose['RAnkle']*2+2]\n",
    "    LHip = X[:,index_alphapose['LHip']*2:index_alphapose['LHip']*2+2]\n",
    "    LKnee = X[:,index_alphapose['LKnee']*2:index_alphapose['LKnee']*2+2]\n",
    "    LAnkle = X[:,index_alphapose['LAnkle']*2:index_alphapose['LAnkle']*2+2]\n",
    "    REye = X[:,index_alphapose['REye']*2:index_alphapose['REye']*2+2]\n",
    "    LEye = X[:,index_alphapose['LEye']*2:index_alphapose['LEye']*2+2]\n",
    "    REar = X[:,index_alphapose['REar']*2:index_alphapose['REar']*2+2]\n",
    "    LEar = X[:,index_alphapose['LEar']*2:index_alphapose['LEar']*2+2]\n",
    "\n",
    "    # Length of head\n",
    "    length_Neck_LEar = euclidean_dist(Neck, LEar)\n",
    "    length_Neck_REar = euclidean_dist(Neck, REar)\n",
    "    length_Neck_LEye = euclidean_dist(Neck, LEye)\n",
    "    length_Neck_REye = euclidean_dist(Neck, REye)\n",
    "    length_Nose_LEar = euclidean_dist(Nose, LEar)\n",
    "    length_Nose_REar = euclidean_dist(Nose, REar)\n",
    "    length_Nose_LEye = euclidean_dist(Nose, LEye)\n",
    "    length_Nose_REye = euclidean_dist(Nose, REye)\n",
    "    length_head      = np.maximum.reduce([length_Neck_LEar, length_Neck_REar, length_Neck_LEye, length_Neck_REye, \\\n",
    "                                 length_Nose_LEar, length_Nose_REar, length_Nose_LEye, length_Nose_REye])\n",
    "\n",
    "    # Length of torso\n",
    "    length_Neck_LHip = euclidean_dist(Neck, LHip)\n",
    "    length_Neck_RHip = euclidean_dist(Neck, RHip)\n",
    "    length_torso     = np.maximum(length_Neck_LHip, length_Neck_RHip)\n",
    "    #length_torso     = np.sqrt(np.square(Neck[:,0:1]-(LHip[:,0:1]+RHip[:,0:1])/2) + np.square(Neck[:,1:2]-(LHip[:,1:2]+RHip[:,1:2])/2))\n",
    "\n",
    "    # Length of right leg\n",
    "    length_leg_right = euclidean_dist(RHip, RKnee) + euclidean_dist(RKnee, RAnkle)\n",
    "  \n",
    "\n",
    "    # Length of left leg\n",
    "    length_leg_left = euclidean_dist(LHip, LKnee) + euclidean_dist(LKnee, LAnkle)\n",
    " \n",
    "\n",
    "    # Length of leg\n",
    "    length_leg = np.maximum(length_leg_right, length_leg_left)\n",
    "\n",
    "    # Length of body\n",
    "    length_body = length_head + length_torso + length_leg\n",
    "    \n",
    "    # Check all samples have length_body of 0\n",
    "    length_chk = (length_body > 0).astype(int)\n",
    "    \n",
    "    # Check keypoints at origin\n",
    "    keypoints_chk = (X > 0).astype(int)\n",
    "    \n",
    "    chk = length_chk * keypoints_chk\n",
    "    \n",
    "    # Set all length_body of 0 to 1 (to avoid division by 0)\n",
    "    length_body[length_body == 0] = 1\n",
    "    \n",
    "    # The center of gravity\n",
    "    # number of point OpenPose locates:\n",
    "    num_pts = (X[:, 0::2] > 0).sum(1).reshape(num_sample,1)\n",
    "    centr_x = X[:, 0::2].sum(1).reshape(num_sample,1) / num_pts\n",
    "\n",
    "    centr_y = X[:, 1::2].sum(1).reshape(num_sample,1) / num_pts\n",
    "\n",
    "\n",
    "    # The  coordinates  are  normalized relative to the length of the body and the center of gravity\n",
    "    X_norm_x = (X[:, 0::2] - centr_x) / length_body\n",
    "    X_norm_y = (X[:, 1::2] - centr_y) / length_body\n",
    "    \n",
    "    # Stack 1st element x and y together\n",
    "    X_norm = np.column_stack((X_norm_x[:,:1], X_norm_y[:,:1]))\n",
    "        \n",
    "    for i in range(1, X.shape[1]//2):\n",
    "        X_norm = np.column_stack((X_norm, X_norm_x[:,i:i+1], X_norm_y[:,i:i+1]))\n",
    "    \n",
    "    # Set all samples have length_body of 0 to origin (0, 0)\n",
    "    X_norm = X_norm * chk\n",
    "    \n",
    "    return X_norm\n",
    "\n",
    "def AlphaPose_Inference(videopath):\n",
    "    args = opt\n",
    "    args.dataset = 'coco'\n",
    "    args.sp = True\n",
    "\n",
    "\n",
    "    if not args.sp:\n",
    "        torch.multiprocessing.set_start_method('forkserver', force=True)\n",
    "        torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "    args.video=videopath\n",
    "    args.outputpath = \"examples/res/\"+os.path.splitext(os.path.basename(videopath))[0]+\"/\"\n",
    "    args.save_video = True\n",
    "    \n",
    "    videofile = args.video\n",
    "    mode = args.mode\n",
    "    if not os.path.exists(args.outputpath):\n",
    "        os.mkdir(args.outputpath)\n",
    "    \n",
    "    if not len(videofile):\n",
    "        raise IOError('Error: must contain --video')\n",
    "\n",
    "    # Load input video\n",
    "    data_loader = VideoLoader(videofile, batchSize=args.detbatch).start()\n",
    "    (fourcc,fps,frameSize) = data_loader.videoinfo()\n",
    "\n",
    "    # Load detection loader\n",
    "    print('Loading YOLO model..')\n",
    "    sys.stdout.flush()\n",
    "    det_loader = DetectionLoader(data_loader, batchSize=args.detbatch).start()\n",
    "    det_processor = DetectionProcessor(det_loader).start()\n",
    "    \n",
    "    # Load pose model\n",
    "    pose_dataset = Mscoco()\n",
    "    if args.fast_inference:\n",
    "        pose_model = InferenNet_fast(4 * 1 + 1, pose_dataset)\n",
    "    else:\n",
    "        pose_model = InferenNet(4 * 1 + 1, pose_dataset)\n",
    "    pose_model.cuda()\n",
    "    pose_model.eval()\n",
    "\n",
    "    runtime_profile = {\n",
    "        'dt': [],\n",
    "        'pt': [],\n",
    "        'pn': []\n",
    "    }\n",
    "\n",
    "    # Data writer\n",
    "    save_path = os.path.join(args.outputpath, 'AlphaPose_'+ntpath.basename(videofile).split('.')[0]+'.avi')\n",
    "    writer = DataWriter(args.save_video, save_path, cv2.VideoWriter_fourcc(*'XVID'), fps, frameSize).start()\n",
    "\n",
    "    im_names_desc =  tqdm(range(data_loader.length()))\n",
    "    batchSize = args.posebatch\n",
    "    for i in im_names_desc:\n",
    "        start_time = getTime()\n",
    "        with torch.no_grad():\n",
    "            (inps, orig_img, im_name, boxes, scores, pt1, pt2) = det_processor.read()\n",
    "            if orig_img is None:\n",
    "                break\n",
    "            if boxes is None or boxes.nelement() == 0:\n",
    "                writer.save(None, None, None, None, None, orig_img, im_name.split('/')[-1])\n",
    "                continue\n",
    "\n",
    "            ckpt_time, det_time = getTime(start_time)\n",
    "            runtime_profile['dt'].append(det_time)\n",
    "            # Pose Estimation\n",
    "            \n",
    "            datalen = inps.size(0)\n",
    "            leftover = 0\n",
    "            if (datalen) % batchSize:\n",
    "                leftover = 1\n",
    "            num_batches = datalen // batchSize + leftover\n",
    "            hm = []\n",
    "            for j in range(num_batches):\n",
    "                inps_j = inps[j*batchSize:min((j +  1)*batchSize, datalen)].cuda()\n",
    "                hm_j = pose_model(inps_j)\n",
    "                hm.append(hm_j)\n",
    "            hm = torch.cat(hm)\n",
    "            ckpt_time, pose_time = getTime(ckpt_time)\n",
    "            runtime_profile['pt'].append(pose_time)\n",
    "\n",
    "            hm = hm.cpu().data\n",
    "            writer.save(boxes, scores, hm, pt1, pt2, orig_img, im_name.split('/')[-1])\n",
    "\n",
    "            ckpt_time, post_time = getTime(ckpt_time)\n",
    "            runtime_profile['pn'].append(post_time)\n",
    "\n",
    "        if args.profile:\n",
    "            # TQDM\n",
    "            im_names_desc.set_description(\n",
    "            'det time: {dt:.3f} | pose time: {pt:.2f} | post processing: {pn:.4f}'.format(\n",
    "                dt=np.mean(runtime_profile['dt']), pt=np.mean(runtime_profile['pt']), pn=np.mean(runtime_profile['pn']))\n",
    "            )\n",
    "\n",
    "    print('===========================> Finish Model Running.')\n",
    "    if (args.save_img or args.save_video) and not args.vis_fast:\n",
    "        print('===========================> Rendering remaining images in the queue...')\n",
    "        print('===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).')\n",
    "    while(writer.running()):\n",
    "        pass\n",
    "    writer.stop()\n",
    "    final_result = writer.results()\n",
    "    write_json(final_result, args.outputpath)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-bumper",
   "metadata": {},
   "source": [
    "## Alpha Pose Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "starting-cyprus",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading YOLO model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/anaconda3/envs/yungtay/lib/python3.7/site-packages/torch/nn/functional.py:2390: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pose model from ./models/sppe/duc_se.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1384/1384 [02:44<00:00,  8.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================> Finish Model Running.\n",
      "===========================> Rendering remaining images in the queue...\n",
      "===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AlphaPose_Inference(\"../2D to 3D Pose/Dataset/Human3.6m/Videos/S1/Videos/Directions 1.54138969.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-improvement",
   "metadata": {},
   "source": [
    "## Convert all Videos in Human3.6M Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "tropical-carbon",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Directions', 'Directions 1.54138969.h5')\n",
      "Directions 1.54138969\n",
      "Loading YOLO model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/anaconda3/envs/yungtay/lib/python3.7/site-packages/torch/nn/functional.py:2390: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pose model from ./models/sppe/duc_se.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1384 [00:00<02:06, 10.95it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-dac2da67ee9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvideopath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../2D to 3D Pose/Dataset/Human3.6m/Videos/S\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/Videos/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".mp4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdone_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlphaPose_Inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../2D to 3D Pose/Dataset/Human3.6m/Videos/S1/Videos/Directions 1.54138969.mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdone_flag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Opening JSON file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-dd71910ef617>\u001b[0m in \u001b[0;36mAlphaPose_Inference\u001b[0;34m(videopath)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0minps_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatalen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 \u001b[0mhm_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpose_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minps_j\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m                 \u001b[0mhm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhm_j\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mhm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yungtay/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ivan/Ivan/Project Lab/THESIS_FALL_DETECTION/AlphaPose/SPPE/src/main_fast_inference.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyranet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yungtay/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ivan/Ivan/Project Lab/THESIS_FALL_DETECTION/AlphaPose/SPPE/src/models/FastPose.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffle1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yungtay/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ivan/Ivan/Project Lab/THESIS_FALL_DETECTION/AlphaPose/SPPE/src/models/layers/SE_Resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 64 * h/4 * w/4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 256 * h/4 * w/4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 512 * h/8 * w/8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 1024 * h/16 * w/16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 2048 * h/32 * w/32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yungtay/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yungtay/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yungtay/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ivan/Ivan/Project Lab/THESIS_FALL_DETECTION/AlphaPose/SPPE/src/models/layers/SE_Resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yungtay/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ivan/Ivan/Project Lab/THESIS_FALL_DETECTION/AlphaPose/SPPE/src/models/layers/SE_module.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yungtay/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yungtay/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yungtay/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yungtay/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yungtay/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Load Human3.6M Video Dataset\n",
    "# Load Human3.6M Skeleton\n",
    "\n",
    "train_2d_file = '/media/ivan/Ivan/Project Lab/THESIS_FALL_DETECTION/2D to 3D Pose/3d_pose_baseline_pytorch/data/train_2d.pth.tar'\n",
    "train_2d = torch.load(train_2d_file)\n",
    "\n",
    "train_2D_Alpha={}\n",
    "for key in train_2d.keys():\n",
    "    print(key)\n",
    "    filename = os.path.splitext(key[2])[0]\n",
    "    videopath = \"../2D to 3D Pose/Dataset/Human3.6m/Videos/S\"+str(key[0])+\"/Videos/\"+os.path.splitext(key[2])[0]+\".mp4\"\n",
    "    print(filename)\n",
    "    done_flag = AlphaPose_Inference(videopath)\n",
    "    if done_flag:\n",
    "        # Opening JSON file \n",
    "        f = open('examples/res/'+filename+'/alphapose-results.json',) \n",
    "\n",
    "        # returns JSON object as  \n",
    "        data = json.load(f) \n",
    "\n",
    "\n",
    "        # Closing file \n",
    "        f.close() \n",
    "\n",
    "        #Normalize Alpha Pose\n",
    "        full_alpha=np.asarray([])\n",
    "\n",
    "        for frame in data:\n",
    "            full_alpha = np.append(full_alpha,data_converter(frame))\n",
    "\n",
    "        full_alpha = full_alpha.reshape(len(data), 34)\n",
    "        alpha_norm = norm_alpha(full_alpha)\n",
    "        train_2D_Alpha[key]=alpha_norm\n",
    "\n",
    "    print(\"Alpha Pose for \" +filename+ \" Done\")\n",
    "\n",
    "a_file = open(\"Human3.6M_AlphaPose.pkl\", \"wb\")\n",
    "pickle.dump(train_2D_Alpha, a_file)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "defensive-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "a_file = open(\"Human3.6M_AlphaPose.pkl\", \"wb\")\n",
    "pickle.dump(train_2D_Alpha, a_file)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-envelope",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
