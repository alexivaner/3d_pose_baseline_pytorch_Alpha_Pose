{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38070b9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hutom\\anaconda3\\envs\\3DPose\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hutom\\anaconda3\\envs\\3DPose\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hutom\\anaconda3\\envs\\3DPose\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hutom\\anaconda3\\envs\\3DPose\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hutom\\anaconda3\\envs\\3DPose\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hutom\\anaconda3\\envs\\3DPose\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\hutom\\anaconda3\\envs\\3DPose\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hutom\\anaconda3\\envs\\3DPose\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hutom\\anaconda3\\envs\\3DPose\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hutom\\anaconda3\\envs\\3DPose\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hutom\\anaconda3\\envs\\3DPose\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hutom\\anaconda3\\envs\\3DPose\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, absolute_import\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import cameras\n",
    "import data_utils\n",
    "import linear_model\n",
    "import procrustes\n",
    "import viz\n",
    "import glob\n",
    "import cdflib\n",
    "sys.argv = sys.argv[:1]\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import data_process as data_process\n",
    "\n",
    "import json \n",
    "from model import LinearModel, OptunaModel, weight_init\n",
    "import torch.nn as nn\n",
    "import utils as utils\n",
    "\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname('__file__'), \"progress\"))\n",
    "\n",
    "from progress.bar import Bar as Bar\n",
    "\n",
    "# Load Human3.6M Skeleton\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pickle\n",
    "\n",
    "tf.app.flags.DEFINE_string(\"action\",\"All\", \"The action to train on. 'All' means all the actions\")\n",
    "\n",
    "# Directories\n",
    "tf.app.flags.DEFINE_string(\"cameras_path\",\"../data/h36m/metadata.xml\", \"File with h36m metadata, including cameras\")\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae89b1f1",
   "metadata": {},
   "source": [
    "# Initiate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20e09f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECT_IDS = [1,5,6,7,8,9,11]\n",
    "this_file = os.path.dirname(os.path.realpath('__file__'))\n",
    "\n",
    "#Load metadata.xml camera\n",
    "rcams = cameras.load_cameras(os.path.join(this_file, FLAGS.cameras_path), SUBJECT_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "647f3e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Joints in H3.6M -- data has 32 joints, but only 17 that move; these are the indices.\n",
    "H36M_NAMES = ['']*32\n",
    "H36M_NAMES[0]  = 'Hip'\n",
    "H36M_NAMES[1]  = 'RHip'\n",
    "H36M_NAMES[2]  = 'RKnee'\n",
    "H36M_NAMES[3]  = 'RFoot'\n",
    "H36M_NAMES[6]  = 'LHip'\n",
    "H36M_NAMES[7]  = 'LKnee'\n",
    "H36M_NAMES[8]  = 'LFoot'\n",
    "H36M_NAMES[12] = 'Spine'\n",
    "H36M_NAMES[13] = 'Thorax'\n",
    "H36M_NAMES[14] = 'Neck/Nose'\n",
    "H36M_NAMES[15] = 'Head'\n",
    "H36M_NAMES[17] = 'LShoulder'\n",
    "H36M_NAMES[18] = 'LElbow'\n",
    "H36M_NAMES[19] = 'LWrist'\n",
    "H36M_NAMES[25] = 'RShoulder'\n",
    "H36M_NAMES[26] = 'RElbow'\n",
    "H36M_NAMES[27] = 'RWrist'\n",
    "\n",
    "index_alphapose={\n",
    "    # Use 17 skeleton point\n",
    "    \"Nose\": 0,\n",
    "    \"RShoulder\": 6,\n",
    "    \"RElbow\": 8,\n",
    "    \"RWrist\": 10,\n",
    "    \"LShoulder\": 5,\n",
    "    \"LElbow\": 7,\n",
    "    \"LWrist\": 9,\n",
    "    \"RHip\": 12,\n",
    "    \"RKnee\": 14,\n",
    "    \"RAnkle\": 16,\n",
    "    \"LHip\": 11,\n",
    "    \"LKnee\": 13,\n",
    "    \"LAnkle\": 15,\n",
    "    \"REye\": 2,\n",
    "    \"LEye\": 1,\n",
    "    \"REar\": 4,\n",
    "    \"LEar\": 3\n",
    "}\n",
    "\n",
    "index_mapping={\n",
    "# Alpha Pose to Human 3.6M\n",
    "\"Hip\": [20, 0],\n",
    "\"RHip\": [12,1],\n",
    "\"RKnee\": [14,2],\n",
    "\"RFoot\": [16,3],\n",
    "\"LHip\": [11,6],\n",
    "\"LKnee\": [13,7],\n",
    "\"LFoot\": [15,8],\n",
    "\"Spine\": [19,12],\n",
    "\"Thorax\": [18,13],\n",
    "# \"Nose\": [14,0],\n",
    "\"Head\": [17,15],\n",
    "\"LShoulder\": [5,17],\n",
    "\"LElbow\": [7,18],\n",
    "\"LWrist\": [9,19],\n",
    "\"RShoulder\": [6,25],\n",
    "\"RElbow\": [8,26],\n",
    "\"RWrist\": [10,27]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "index_mapping_nose={\n",
    "# Alpha Pose to Human 3.6M\n",
    "\"Hip\": [20, 0],\n",
    "\"RHip\": [12,1],\n",
    "\"RKnee\": [14,2],\n",
    "\"RFoot\": [16,3],\n",
    "\"LHip\": [11,6],\n",
    "\"LKnee\": [13,7],\n",
    "\"LFoot\": [15,8],\n",
    "\"Spine\": [19,12],\n",
    "\"Thorax\": [18,13],\n",
    "\"Nose\": [0,14],\n",
    "\"Head\": [17,15],\n",
    "\"LShoulder\": [5,17],\n",
    "\"LElbow\": [7,18],\n",
    "\"LWrist\": [9,19],\n",
    "\"RShoulder\": [6,25],\n",
    "\"RElbow\": [8,26],\n",
    "\"RWrist\": [10,27]\n",
    "}\n",
    "\n",
    "\n",
    "def data_converter(data):\n",
    "    data=data['keypoints']\n",
    "    keypoints=[]\n",
    "    kp_score=[]\n",
    "    for a in range (0,len(data)):\n",
    "        score=[]\n",
    "        if ((a+3)%3==0):\n",
    "            keypoints.append(data[a])\n",
    "            keypoints.append(data[a+1])\n",
    "        elif((a+1)%3==0):\n",
    "            score=data[a]\n",
    "            kp_score.append(score)\n",
    "\n",
    "    return keypoints\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "stat_3D = torch.load('../data/stat_3d.pth.tar')\n",
    "stat_2D = torch.load('../data/stat_2d.pth.tar')\n",
    "\n",
    "data_mean_2d, data_std_2d, dim_to_ignore_2d, dim_to_use_2d = stat_2D['mean'],stat_2D['std'],stat_2D['dim_ignore'],stat_2D['dim_use']\n",
    "data_mean_3d, data_std_3d, dim_to_ignore_3d, dim_to_use_3d = stat_3D['mean'],stat_3D['std'],stat_3D['dim_ignore'],stat_3D['dim_use']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2efca7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def count_head(alpha_pose):\n",
    "    x = (alpha_pose[index_alphapose['LEar']*2]+alpha_pose[index_alphapose['REar']*2])/2\n",
    "    y = (alpha_pose[index_alphapose['LEar']*2+1]+alpha_pose[index_alphapose['REar']*2+1])/2\n",
    "    return x,y\n",
    "\n",
    "\n",
    "def count_thorax(alpha_pose):\n",
    "    x = (alpha_pose[index_alphapose['LShoulder']*2]+alpha_pose[index_alphapose['RShoulder']*2])/2\n",
    "    y = (alpha_pose[index_alphapose['LShoulder']*2+1]+alpha_pose[index_alphapose['RShoulder']*2+1])/2\n",
    "    return x,y\n",
    "\n",
    "\n",
    "def count_spine(alpha_pose):\n",
    "    hip_x,hip_y=count_hip(alpha_pose)\n",
    "    thorax_x,thorax_y=count_thorax(alpha_pose)\n",
    "    x = (hip_x+thorax_x)/2\n",
    "    y = (hip_y+thorax_y)/2\n",
    "    return x,y\n",
    "\n",
    "def count_hip(alpha_pose):\n",
    "    x = (alpha_pose[index_alphapose['LHip']*2]+alpha_pose[index_alphapose['RHip']*2])/2\n",
    "    y = (alpha_pose[index_alphapose['LHip']*2+1]+alpha_pose[index_alphapose['RHip']*2+1])/2\n",
    "    return x,y\n",
    "\n",
    "def add_features(alpha_pose):\n",
    "    #Count Head\n",
    "    head_x,head_y=count_head(alpha_pose)\n",
    "    alpha_pose=np.append(alpha_pose,(head_x,head_y))\n",
    "    \n",
    "    #Count Thorax\n",
    "    thorax_x,thorax_y=count_thorax(alpha_pose)\n",
    "    alpha_pose=np.append(alpha_pose,(thorax_x,thorax_y))\n",
    " \n",
    "    \n",
    "    #Count Spine\n",
    "    spine_x,spine_y=count_spine(alpha_pose)\n",
    "    alpha_pose=np.append(alpha_pose,(spine_x,spine_y))\n",
    "    \n",
    "    #Count Hip\n",
    "    hip_x,hip_y=count_hip(alpha_pose)\n",
    "    alpha_pose=np.append(alpha_pose,(hip_x,hip_y))\n",
    "    \n",
    "    return alpha_pose\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcadb83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is not includding nose for 2D to 3D\n",
    "def map_alpha_to_human(alpha_pose):\n",
    "    alpha_pose=add_features(alpha_pose)\n",
    "    temp_list = [None] * 64\n",
    "    for a,b in index_mapping.items():\n",
    "        temp_list[b[1]*2]=alpha_pose[b[0]*2]\n",
    "        temp_list[b[1]*2+1]=alpha_pose[b[0]*2+1]\n",
    "    human36m=np.asarray(temp_list)\n",
    "    return human36m\n",
    "\n",
    "#This function is includding nose for classification\n",
    "def map_alpha_to_human_classification(alpha_pose):\n",
    "    alpha_pose=add_features(alpha_pose)\n",
    "    temp_list = [None] * 64\n",
    "    for a,b in index_mapping_nose.items():\n",
    "        temp_list[b[1]*2]=alpha_pose[b[0]*2]\n",
    "        temp_list[b[1]*2+1]=alpha_pose[b[0]*2+1]\n",
    "    human36m=np.asarray(temp_list)\n",
    "    return human36m\n",
    "\n",
    "\n",
    "def map_alpha_to_human_classification_json(path):\n",
    "    # Opening JSON file \n",
    "    f = open(path) \n",
    "    converted=[]\n",
    "    # returns JSON object as  \n",
    "    # a dictionary \n",
    "    data = json.load(f) \n",
    "\n",
    "    for dat in data:\n",
    "        convert=np.asarray(data_converter(dat))\n",
    "        human36m_alpha_example=map_alpha_to_human_classification(convert)\n",
    "        human36m_alpha_example=human36m_alpha_example.astype('float')\n",
    "        converted.append(human36m_alpha_example)\n",
    "\n",
    "    converted=np.asarray(converted) \n",
    "        \n",
    "    # Closing file \n",
    "    f.close() \n",
    "    \n",
    "    return converted\n",
    "\n",
    "def find_centroid(skeletons):\n",
    "    centroids=[]\n",
    "    for skeleton in skeletons:\n",
    "        skeleton_test=skeleton.reshape(int(96/3),3)\n",
    "        centroid=np.mean(skeleton_test, axis=0)\n",
    "        centroids.append(centroid)\n",
    "    centroids=np.asarray(centroids)\n",
    "    return centroids\n",
    "\n",
    "def rotate(origin, skeletons, angle):\n",
    "    \"\"\"\n",
    "    Rotate a point counterclockwise by a given angle around a given origin.\n",
    "\n",
    "    The angle should be given in radians.\n",
    "    \"\"\"\n",
    "    rotated=[]\n",
    "    for i,skeleton in enumerate(skeletons):\n",
    "        joints=[]\n",
    "        skeleton_test=skeleton.reshape(int(96/3),3)\n",
    "        angle_xy,angle_xz,angle_yz=math.radians(angle[0]),math.radians(angle[1]),math.radians(angle[2])\n",
    "        \n",
    "        for j,join in enumerate(skeleton_test):\n",
    "            ox, oy,oz = origin[i][0],origin[i][1],origin[i][2]\n",
    "            px, py,pz = join[0],join[1],join[2]\n",
    "\n",
    "            #Rotation XY\n",
    "            qx = ox + math.cos(angle_xy) * (px - ox) - math.sin(angle_xy) * (py - oy)\n",
    "            qy = oy + math.sin(angle_xy) * (px - ox) + math.cos(angle_xy) * (py - oy)\n",
    "            px, py,pz=qx,qy,pz\n",
    "            \n",
    "            #Rotation XZ\n",
    "            qx = ox + math.cos(angle_xz) * (px - ox) - math.sin(angle_xz) * (pz - oz)\n",
    "            qz = oz + math.sin(angle_xz) * (px - ox) + math.cos(angle_xz) * (pz - oz)\n",
    "            px, py,pz=qx,py,qz\n",
    "            \n",
    "            #Rotation YZ\n",
    "            qy = oy + math.cos(angle_yz) * (py - oy) - math.sin(angle_yz) * (pz - oz)\n",
    "            qz = oz + math.sin(angle_yz) * (py - oy) + math.cos(angle_yz) * (pz - oz)\n",
    "            px, py,pz=px,qy,qz\n",
    "\n",
    "            joints.append(px)\n",
    "            joints.append(py)\n",
    "            joints.append(pz)\n",
    "\n",
    "\n",
    "        rotated.append(joints)\n",
    "    rotated=np.asarray(rotated)\n",
    "    return rotated\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1d2f3a",
   "metadata": {},
   "source": [
    "# Do 3D Prediction from Custom Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1d68ca",
   "metadata": {},
   "source": [
    "## Using Created Statistic Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcd1233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize=True\n",
    "actions = data_utils.define_actions( FLAGS.action )\n",
    "# Human3.6m IDs for training and testing\n",
    "TRAIN_SUBJECTS = [1,5,6,7,8]\n",
    "TEST_SUBJECTS  = [9,11]\n",
    "\n",
    "\n",
    "stat_3D = torch.load('../data/stat_3d.pth.tar')\n",
    "stat_2D = torch.load('../data/stat_2d.pth.tar')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4ea3030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_mean_2d, data_std_2d, dim_to_ignore_2d, dim_to_use_2d = stat_2D['mean'],stat_2D['std'],stat_2D['dim_ignore'],stat_2D['dim_use']\n",
    "data_mean_3d, data_std_3d, dim_to_ignore_3d, dim_to_use_3d = stat_3D['mean'],stat_3D['std'],stat_3D['dim_ignore'],stat_3D['dim_use']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1c3aa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the json data\n",
    "#load json data using json,load(f)\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "class Human36M_testing(Dataset):\n",
    "    def __init__(self, skeleton,many=False):\n",
    "        \"\"\"\n",
    "        :param actions: list of actions to use\n",
    "        :param data_path: path to dataset\n",
    "        :param use_hg: use stacked hourglass detections\n",
    "        :param is_train: load train/test dataset\n",
    "        \"\"\"\n",
    "\n",
    "        self.test_inp, self.test_out = [], []\n",
    "\n",
    "        # loading data\n",
    "        # load test data\n",
    "       \n",
    "        if many:\n",
    "            num_f= skeleton.shape\n",
    "            for i in range(num_f[0]):\n",
    "                self.test_inp.append(skeleton[i])\n",
    "        else:\n",
    "            self.test_inp.append(skeleton)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        inputs = torch.from_numpy(self.test_inp[index]).float()\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.test_inp)\n",
    "    \n",
    "def normalize_single_data(data, data_mean, data_std, dim_to_use ):\n",
    "    \"\"\"Normalizes a dictionary of poses\n",
    "\n",
    "    Args\n",
    "    data: dictionary where values are\n",
    "    data_mean: np vector with the mean of the data\n",
    "    data_std: np vector with the standard deviation of the data\n",
    "    dim_to_use: list of dimensions to keep in the data\n",
    "    Returns\n",
    "    data_out: dictionary with same keys as data, but values have been normalized\n",
    "    \"\"\"\n",
    "\n",
    "    data= data[dim_to_use]\n",
    "    mu = data_mean[dim_to_use]\n",
    "    stddev = data_std[dim_to_use]\n",
    "    data_out= np.divide( (data - mu), stddev )\n",
    "\n",
    "    return data_out\n",
    "def create_datatest(data):\n",
    "    converted=[]\n",
    "    for dat in data:\n",
    "        convert=np.asarray(data_converter(dat))\n",
    "        human36m_alpha_example=map_alpha_to_human(convert)\n",
    "        normalized=normalize_single_data(human36m_alpha_example,data_mean_2d,data_std_2d,dim_to_use_2d)\n",
    "        normalized=normalized.astype('float')\n",
    "        converted.append(normalized)\n",
    "\n",
    "    converted=np.asarray(converted) \n",
    "    test_loader = DataLoader(\n",
    "        dataset=Human36M_testing(converted,True),\n",
    "        batch_size=1024,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True)\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55367994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a1d7273",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "14c85fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> creating model\n",
      ">>> total params: 10.60M\n",
      ">>> loading ckpt from '../checkpoint/optuna/ckpt_best_1.pth.tar'\n",
      ">>> ckpt loaded (epoch: 29 | err: 40.643307541837174)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "model_path='../checkpoint/optuna/ckpt_best_1.pth.tar'\n",
    "# create model\n",
    "print(\">>> creating model\")\n",
    "#model = LinearModel()\n",
    "model = OptunaModel()\n",
    "model = model.cuda()\n",
    "model.apply(weight_init)\n",
    "print(\">>> total params: {:.2f}M\".format(sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "criterion = nn.MSELoss(size_average=True).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-3)\n",
    "\n",
    "print(\">>> loading ckpt from '{}'\".format('../checkpoint/optuna/ckpt_best_1.pth.tar'))\n",
    "ckpt = torch.load(model_path)\n",
    "start_epoch = ckpt['epoch']\n",
    "err_best = ckpt['err']\n",
    "glob_step = ckpt['step']\n",
    "lr_now = ckpt['lr']\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "optimizer.load_state_dict(ckpt['optimizer'])\n",
    "print(\">>> ckpt loaded (epoch: {} | err: {})\".format(start_epoch, err_best))\n",
    "\n",
    "new_stat_3d={}\n",
    "new_stat_3d['mean']=data_mean_3d\n",
    "new_stat_3d['std']=data_std_3d\n",
    "new_stat_3d['dim_use']=dim_to_use_3d\n",
    "new_stat_3d['dim_ignore']=dim_to_ignore_3d\n",
    "    \n",
    "def test(test_loader, model, criterion, stat_3d, procrustes=False):\n",
    "    losses = utils.AverageMeter()\n",
    "    model.eval()\n",
    "\n",
    "    all_dist = []\n",
    "    pred_result=[]\n",
    "    start = time.time()\n",
    "    batch_time = 0\n",
    "    bar = Bar('>>>', fill='>', max=len(test_loader))\n",
    "\n",
    "    for i, inps in enumerate(test_loader):\n",
    "        inputs = Variable(inps.cuda())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        # calculate erruracy\n",
    "        print(outputs.shape)\n",
    "        outputs_unnorm = data_process.unNormalizeData(outputs.data.cpu().numpy(), stat_3d['mean'], stat_3d['std'], stat_3d['dim_use'])\n",
    "\n",
    "        # remove dim ignored\n",
    "        dim_use = np.hstack((np.arange(3), stat_3d['dim_use']))\n",
    "\n",
    "        outputs_use = outputs_unnorm[:, dim_use]\n",
    "        pred_result.append(outputs_unnorm)\n",
    "        \n",
    "        # update summary\n",
    "        if (i + 1) % 100 == 0:\n",
    "            batch_time = time.time() - start\n",
    "            start = time.time()\n",
    "\n",
    "        bar.suffix = '({batch}/{size}) | batch: {batchtime:.4}ms | Total: {ttl} | ETA: {eta:} | loss: {loss:.6f}' \\\n",
    "            .format(batch=i + 1,\n",
    "                    size=len(test_loader),\n",
    "                    batchtime=batch_time * 10.0,\n",
    "                    ttl=bar.elapsed_td,\n",
    "                    eta=bar.eta_td,\n",
    "                    loss=losses.avg)\n",
    "        bar.next()\n",
    "    bar.finish()\n",
    "    return pred_result\n",
    "\n",
    "# Combine prediction from each batch into one prediction\n",
    "def combine_prediction(pred_result_all):\n",
    "    prediction_list = []\n",
    "    for pred in pred_result_all:\n",
    "        for pre in pred:\n",
    "            prediction_list.append(pre)\n",
    "    prediction_list=np.asarray(prediction_list)\n",
    "    return prediction_list\n",
    "\n",
    "\n",
    "def correct_3D(poses3d_input,poses2d_normalized):\n",
    "    _max = 0\n",
    "    _min = 10000\n",
    "    poses3d=np.copy(poses3d_input)\n",
    "    \n",
    "    spine_x = poses2d_normalized[0][24]\n",
    "    spine_y = poses2d_normalized[0][25]\n",
    "            \n",
    "    \n",
    "    for i in range(poses3d.shape[0]):\n",
    "\n",
    "        for j in range(32):\n",
    "\n",
    "            tmp = poses3d[i][j * 3 + 2]\n",
    "            poses3d[i][j * 3 + 2] = poses3d[i][j * 3 + 1]\n",
    "            poses3d[i][j * 3 + 1] = tmp\n",
    "            if poses3d[i][j * 3 + 2] > _max:\n",
    "                _max = poses3d[i][j * 3 + 2]\n",
    "                print(\"_max: \",_max)\n",
    "            if poses3d[i][j * 3 + 2] < _min:\n",
    "                _min = poses3d[i][j * 3 + 2]\n",
    "                print(\"_min: \",_min)\n",
    "\n",
    "    for i in range(poses3d.shape[0]):\n",
    "        for j in range(32):\n",
    "            poses3d[i][j * 3 + 2] = _max - poses3d[i][j * 3 + 2] + _min\n",
    "            poses3d[i][j * 3] += (spine_x - 630)\n",
    "            poses3d[i][j * 3 + 2] += (500 - spine_y)\n",
    "\n",
    "    return poses3d\n",
    "\n",
    "def inferencealphaposeto3D(path,fixing=False,save_npy=False):\n",
    "    # Opening JSON file \n",
    "    f = open(path) \n",
    "\n",
    "    # returns JSON object as  \n",
    "    # a dictionary \n",
    "    data = json.load(f) \n",
    "\n",
    "\n",
    "    # Closing file \n",
    "    f.close() \n",
    "    \n",
    "    #Create Datatest for 2D to 3D Inference\n",
    "    all_test_data=create_datatest(data)\n",
    "    \n",
    "    #Doing Inference\n",
    "    pred_result_all=test(all_test_data, model, criterion, new_stat_3d) #All\n",
    "    \n",
    "    #Combine Prediction Result\n",
    "    prediction_list=combine_prediction(pred_result_all)\n",
    "    \n",
    "    if fixing:\n",
    "        #Fixing for unity\n",
    "        test_2d_normalized = np.asarray(all_test_data.dataset.test_inp) \n",
    "        fixed=correct_3D(prediction_list,test_2d_normalized)\n",
    "    else:\n",
    "        fixed=prediction_list\n",
    "    \n",
    "    centroids=find_centroid(fixed)\n",
    "    angles=[0,0,260]\n",
    "    rotated_skeletons=rotate(centroids,fixed, angles)  \n",
    "    human3d = rotated_skeletons - np.tile( rotated_skeletons[:,:3], [1, len(H36M_NAMES)] )\n",
    "\n",
    "    if save_npy:\n",
    "        base=os.path.basename(path)\n",
    "        base=os.path.splitext(base)[0]\n",
    "\n",
    "        with open('../inference_result_npy/'+base+'.npy', 'wb') as f:\n",
    "            np.save(f, human3d)\n",
    "    \n",
    "\n",
    "    return human3d\n",
    "\n",
    "import h5py\n",
    "\n",
    "def load_cameras(bpath='cameras.h5', subjects=None):\n",
    "    \"\"\"\n",
    "    :param bpath: *.h5\n",
    "    :param subjects:\n",
    "    :return: (dict)\n",
    "    \"\"\"\n",
    "\n",
    "    if subjects is None:\n",
    "        subjects = [1, 5, 6, 7, 8, 9, 11]\n",
    "    rcams = {}\n",
    "\n",
    "    with h5py.File(bpath, 'r') as hf:\n",
    "        for s in subjects:\n",
    "            for c in range(4):  # There are 4 cameras in human3.6m\n",
    "                a = load_camera_params(hf, 'subject%d/camera%d/{0}' % (s, c + 1))\n",
    "                rcams[(s, c + 1)] = a\n",
    "\n",
    "    return rcams\n",
    "\n",
    "\n",
    "def map3dto2dcamera( poses_set, cams, ncams=4 ):\n",
    "    \"\"\"\n",
    "    Project 3d poses using camera parameters\n",
    "\n",
    "    cams: dictionary with camera parameters\n",
    "    ncams: number of cameras per subject\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    for cam in range( ncams ):\n",
    "        R, T, f, c, k, p, name = cams[ (11, cam+1) ]\n",
    "        pts2d, _, _, _, _ = project_point_radial( np.reshape(poses_set, [-1, 3]), R, T, f, c, k, p )\n",
    "\n",
    "        pts2d = np.reshape( pts2d, [-1, len(H36M_NAMES)*2] )\n",
    "\n",
    "    return pts2d\n",
    "\n",
    "def project_point_radial(P, R, T, f, c, k, p):\n",
    "    \"\"\"\n",
    "    Args\n",
    "    P: Nx3 points in world coordinates\n",
    "    R: 3x3 Camera rotation matrix\n",
    "    T: 3x1 Camera translation parameters\n",
    "    f: 2x1 (scalar) Camera focal length\n",
    "    c: 2x1 Camera center\n",
    "    k: 3x1 Camera radial distortion coefficients\n",
    "    p: 2x1 Camera tangential distortion coefficients\n",
    "    Returns\n",
    "    Proj: Nx2 points in pixel space\n",
    "    D: 1xN depth of each point in camera space\n",
    "    radial: 1xN radial distortion per point\n",
    "    tan: 1xN tangential distortion per point\n",
    "    r2: 1xN squared radius of the projected points before distortion\n",
    "    \"\"\"\n",
    "\n",
    "    # P is a matrix of 3-dimensional points\n",
    "    assert len(P.shape) == 2\n",
    "    assert P.shape[1] == 3\n",
    "\n",
    "    N = P.shape[0]\n",
    "    X = R.dot(P.T - T)  # rotate and translate\n",
    "    XX = X[:2, :] / X[2, :]  # 2x16\n",
    "    r2 = XX[0, :] ** 2 + XX[1, :] ** 2  # 16,\n",
    "\n",
    "    radial = 1 + np.einsum('ij,ij->j', np.tile(k, (1, N)), np.array([r2, r2 ** 2, r2 ** 3]))  # 16,\n",
    "    tan = p[0] * XX[1, :] + p[1] * XX[0, :]  # 16,\n",
    "\n",
    "    tm = np.outer(np.array([p[1], p[0]]).reshape(-1), r2)  # 2x16\n",
    "\n",
    "    XXX = XX * np.tile(radial + tan, (2, 1)) + tm  # 2x16\n",
    "\n",
    "    Proj = (f * XXX) + c  # 2x16\n",
    "    Proj = Proj.T\n",
    "\n",
    "    D = X[2, ]\n",
    "\n",
    "    return Proj, D, radial, tan, r2\n",
    "\n",
    "\n",
    "def mapto2D(skeletons,rcams):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    skeleton2D=[]\n",
    "    for i,skeleton in enumerate(skeletons):\n",
    "        mapped=map3dto2dcamera(skeleton,rcams,4)\n",
    "        skeleton2D.append(mapped)\n",
    "    skeleton2D=np.asarray(skeleton2D)\n",
    "    skeleton2D=skeleton2D.reshape(skeleton2D.shape[0],64)\n",
    "    return skeleton2D\n",
    "\n",
    "SUBJECT_IDS = [1,5,6,7,8,9,11]\n",
    "this_file = os.path.dirname(os.path.realpath('__file__'))\n",
    "rcams = cameras.load_cameras(os.path.join(this_file, \"../data/h36m/metadata.xml\"), SUBJECT_IDS)\n",
    "\n",
    "\n",
    "\n",
    "def find_transformation_3D(skeleton_a,skeleton_b,fullskeleton):\n",
    "    \n",
    "    # remove dim ignored\n",
    "    dim_use = np.hstack((np.arange(3), new_stat_3d['dim_use']))\n",
    "\n",
    "    gt = skeleton_a[dim_use]\n",
    "    out = skeleton_b[dim_use]\n",
    "    gt = gt.reshape(-1, 3)\n",
    "    out = out.reshape(-1, 3)\n",
    "    _, Z, T, b, c = get_transformation(gt, out, True)\n",
    "    transformation_value={\"T\":T,\"b\":b,\"c\":c}\n",
    "    \n",
    "    skeleton3D=[]\n",
    "    for i,skeleton in enumerate(fullskeleton):\n",
    "        skeleton = skeleton.reshape(-1, 3)\n",
    "        skeleton = (b * skeleton.dot(T)) + c\n",
    "        skeleton3D.append(skeleton)\n",
    "    skeleton3D=np.asarray(skeleton3D)\n",
    "    skeleton3D=skeleton3D.reshape(skeleton3D.shape[0],96)\n",
    "\n",
    "    return  skeleton3D,transformation_value\n",
    "    \n",
    "def find_pair_transformation(path_1,pose_class_1,image_id_1,path_2,pose_class_2,image_id_2):\n",
    "    with open(path_1, 'rb') as f:\n",
    "        angle1 = json.load(f)\n",
    "    with open(path_2, 'rb') as f:\n",
    "        angle2 = json.load(f)\n",
    "    \n",
    "    angle1_temp=[]\n",
    "    angle1_all=[]\n",
    "\n",
    "    for a in angle1:\n",
    "        if (a['pose_class']==pose_class_1) and (a['image_id']==image_id_1):\n",
    "            angle1_temp.append(a)\n",
    "    \n",
    "\n",
    "    angle2_before=[]\n",
    "    angle2_all=[]\n",
    "    for a in angle2:\n",
    "        if (a['pose_class']==pose_class_2) and (a['image_id']==image_id_2):\n",
    "            angle2_before.append(a)\n",
    "        angle2_all.append(a['visualize'])\n",
    "    \n",
    "    angle2_transformed_3D,transformation_value=find_transformation_3D(np.asarray(angle1_temp[0]['visualize']),\n",
    "                                             np.asarray(angle2_before[0]['visualize']),\n",
    "                                             np.asarray(angle2_all))\n",
    "    \n",
    "\n",
    "    return angle2_transformed_3D,transformation_value\n",
    "\n",
    "def get_transformation(X, Y, compute_optimal_scale=True):\n",
    "    muX = X.mean(0)\n",
    "    muY = Y.mean(0)\n",
    "\n",
    "    X0 = X - muX\n",
    "    Y0 = Y - muY\n",
    "\n",
    "    ssX = (X0 ** 2.).sum()\n",
    "    ssY = (Y0 ** 2.).sum()\n",
    "\n",
    "    # centred Frobenius norm\n",
    "    normX = np.sqrt(ssX)\n",
    "    normY = np.sqrt(ssY)\n",
    "\n",
    "    # scale to equal (unit) norm\n",
    "    X0 = X0 / normX\n",
    "    Y0 = Y0 / normY\n",
    "\n",
    "    # optimum rotation matrix of Y\n",
    "    A = np.dot(X0.T, Y0)\n",
    "    U, s, Vt = np.linalg.svd(A, full_matrices=False)\n",
    "    V = Vt.T\n",
    "    T = np.dot(V, U.T)\n",
    "\n",
    "    # Make sure we have a rotation\n",
    "    detT = np.linalg.det(T)\n",
    "    V[:, -1] *= np.sign(detT)\n",
    "    s[-1] *= np.sign(detT)\n",
    "    T = np.dot(V, U.T)\n",
    "\n",
    "    traceTA = s.sum()\n",
    "\n",
    "    if compute_optimal_scale:  # Compute optimum scaling of Y.\n",
    "        b = traceTA * normX / normY\n",
    "        d = 1 - traceTA ** 2\n",
    "        Z = normX * traceTA * np.dot(Y0, T) + muX\n",
    "    else:  # If no scaling allowed\n",
    "        b = 1\n",
    "        d = 1 + ssY / ssX - 2 * traceTA * normY / normX\n",
    "        Z = normY * np.dot(Y0, T) + muX\n",
    "\n",
    "    c = muX - b * np.dot(muY, T)\n",
    "\n",
    "    return d, Z, T, b, c\n",
    "\n",
    "def save_transformation(transformed_value,output_path,path_1,pose_class_1,image_id_1,path_2,pose_class_2,image_id_2):\n",
    "    base_1= os.path.splitext(os.path.basename(path_1))[0]\n",
    "    base_2= os.path.splitext(os.path.basename(path_2))[0]\n",
    "    transformed_value['Reference_Path']=base_1\n",
    "    transformed_value['Reference_Pose_Class']=pose_class_1\n",
    "    transformed_value['Reference_Image_ID']=image_id_1\n",
    "    transformed_value['Transformed_Path']=base_2\n",
    "    transformed_value['Transformed_Pose_Class']=pose_class_2\n",
    "    transformed_value['Transformed_Image_ID']=image_id_2\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        import cPickle as pickle\n",
    "    except ImportError:  # Python 3.x\n",
    "        import pickle\n",
    "        \n",
    "    with open(output_path, 'wb') as fp:\n",
    "        pickle.dump(transformed_value, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def save_to_json(result_3D, input_path, output_path):\n",
    "    f = open(input_path) \n",
    "    dim_use = np.hstack((np.arange(3), dim_to_use_3d))\n",
    "\n",
    "    # returns JSON object as  \n",
    "    # a dictionary \n",
    "    data = json.load(f) \n",
    "    \n",
    "    for a,b in zip(data,result_3D):\n",
    "        a['keypoints']=b[dim_use].tolist()\n",
    "        a['visualize']=b.tolist()\n",
    "        \n",
    "    with open(output_path, 'w') as fp:\n",
    "        fp.write(json.dumps(data))\n",
    "    \n",
    "def save_to_json_2D(result_2D, input_path, output_path):\n",
    "    f = open(input_path) \n",
    "\n",
    "    # returns JSON object as  \n",
    "    # a dictionary \n",
    "    data = json.load(f) \n",
    "    \n",
    "    a=dim_to_use_2d.tolist()\n",
    "    a.insert(18,28)\n",
    "    a.insert(19,29)\n",
    "    dim_to_use_2d_nose=np.asarray(a)\n",
    "\n",
    "    for a,b in zip(data,result_2D):\n",
    "        a['keypoints']=b[dim_to_use_2d_nose].tolist()\n",
    "        \n",
    "    with open(output_path, 'w') as fp:\n",
    "        fp.write(json.dumps(data))\n",
    "        \n",
    "def save_to_json_original2D(result_2D, input_path, output_path):\n",
    "    f = open(input_path) \n",
    "\n",
    "    # returns JSON object as  \n",
    "    # a dictionary \n",
    "    data = json.load(f) \n",
    "    \n",
    "    a=dim_to_use_2d.tolist()\n",
    "    a.insert(18,28)\n",
    "    a.insert(19,29)\n",
    "    dim_to_use_2d_nose=np.asarray(a)\n",
    "\n",
    "\n",
    "    for a,b in zip(data,result_2D):\n",
    "        a['keypoints']=b[dim_to_use_2d_nose].tolist()\n",
    "        \n",
    "    with open(output_path, 'w') as fp:\n",
    "        fp.write(json.dumps(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9d28be",
   "metadata": {},
   "source": [
    "Inference to json to three kinds:\n",
    "1. Original 3D Baseline\n",
    "2. 3D After doing proscrutes to another angle\n",
    "3. 2D Mapping after doing proscrutes to another angle\n",
    "4. Eucledian normalization of 2D Mapping after doing proscrutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bcc8df",
   "metadata": {},
   "source": [
    "## Original 3D Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e99e1cb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([642, 48])\n",
      "Wall time: 289 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path='../json_test/6-FallingDown.json'\n",
    "base= os.path.splitext(os.path.basename(path))[0]\n",
    "inference_result=inferencealphaposeto3D(path,fixing=False,save_npy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1309e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path='../inference_result_npy/'+base+'_3D_Original.json'\n",
    "save_to_json(inference_result, path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602789be",
   "metadata": {},
   "source": [
    "## Original 2D Human3.6m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa483a01",
   "metadata": {},
   "source": [
    "This will save alpha pose in human3.6m format that have nose inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "18fdbeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path='../inference_result_npy/'+base+'_2D_Original.json'\n",
    "mapping_result=map_alpha_to_human_classification_json(path)\n",
    "save_to_json_original2D(mapping_result, path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2898278d",
   "metadata": {},
   "source": [
    "## 2D Map from Original 3DHuman3.6m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2341214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton2d_original=mapto2D(inference_result,rcams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "62edc5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(642, 64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skeleton2d_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c214c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path='../inference_result_npy/'+base+'_2D_from3DOriginal.json'\n",
    "save_to_json_2D(skeleton2d_original, path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f12821c",
   "metadata": {},
   "source": [
    "## 3D After doing proscrutes to another angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cef6dc28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reference\n",
    "path_1='../inference_result_npy/taoyuan_angle1_3D_Original.json'\n",
    "pose_class_1=\"Standing_01\"\n",
    "image_id_1= '04363.png'\n",
    "\n",
    "#Want to transform\n",
    "path_2='../inference_result_npy/2_3D_Original.json'\n",
    "pose_class_2=\"Standing\"\n",
    "image_id_2= '00674.jpg'\n",
    "\n",
    "base_1= os.path.splitext(os.path.basename(path_1))[0]\n",
    "base_2= os.path.splitext(os.path.basename(path_2))[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "46f74e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save transformation only\n",
    "\n",
    "transformed1,transformation_value1=find_pair_transformation(path_1,pose_class_1,image_id_1,path_2,pose_class_2,image_id_2)\n",
    "output_path='../inference_result_npy/'+base_2+\" to \"+base_1+'_transformationvalue.pickle'\n",
    "save_transformation(transformation_value1, output_path,path_1,pose_class_1,image_id_1,path_2,pose_class_2,image_id_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dbf7f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Full Skeleton\n",
    "\n",
    "output_path='../inference_result_npy/'+base_2+\" to \"+base_1+'_proscrustes.json'\n",
    "save_to_json(transformed1, path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d92dc54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save transformation for augmented \n",
    "\n",
    "transformed2,transformation_value2=find_pair_transformation(path_2,pose_class_2,image_id_2,path_1,pose_class_1,image_id_1)\n",
    "output_path='../inference_result_npy/'+base_1+\" to \"+base_2+'_transformationvalue_augmentdataset.pickle'\n",
    "save_transformation(transformation_value2, output_path,path_2,pose_class_2,image_id_2,path_1,pose_class_1,image_id_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3fb36c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Full Skeleton\n",
    "\n",
    "output_path='../inference_result_npy/'+base_1+\" to \"+base_2+'_proscrustes.json'\n",
    "save_to_json(transformed2, path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97db0f60",
   "metadata": {},
   "source": [
    "## 2D Mapping after doing proscrutes to another angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fc55548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "skeleton2d=mapto2D(transformed,rcams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48414e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path='../inference_result_npy/'+base+'_2D_Proscrutes.json'\n",
    "save_to_json_2D(skeleton2d, path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fb0a19",
   "metadata": {},
   "source": [
    "## Normalize using Eucledian Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "649762e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_human36m={\n",
    "    # Use 16 skeleton point\n",
    "    \"Pelvis\": 0,\n",
    "    \"Head\": 15,\n",
    "    \"Thorax\":13,\n",
    "    \"RShoulder\": 25,\n",
    "    \"RElbow\": 26,\n",
    "    \"RWrist\": 27,\n",
    "    \"LShoulder\": 17,\n",
    "    \"LElbow\": 18,\n",
    "    \"LWrist\": 19,\n",
    "    \"RHip\": 1,\n",
    "    \"RKnee\": 2,\n",
    "    \"RAnkle\": 3,\n",
    "    \"LHip\": 6,\n",
    "    \"LKnee\": 7,\n",
    "    \"LAnkle\": 8,\n",
    "    \"Spine\" : 12\n",
    "}\n",
    "\n",
    "def euclidean_dist(a, b):\n",
    "    # This function calculates the euclidean distance between 2 point in 2-D coordinates\n",
    "    # if one of two points is (0,0), dist = 0\n",
    "    # a, b: input array with dimension: m, 2\n",
    "    # m: number of samples\n",
    "    # 2: x and y coordinate\n",
    "    try:\n",
    "        if (a.shape[1] == 2 and a.shape == b.shape):\n",
    "            # check if element of a and b is (0,0)\n",
    "            bol_a = (a[:,0] != 0).astype(int)\n",
    "            bol_b = (b[:,0] != 0).astype(int)\n",
    "            dist = np.linalg.norm(a-b, axis=1)\n",
    "            return((dist*bol_a*bol_b).reshape(a.shape[0],1))\n",
    "    except:\n",
    "        print(\"[Error]: Check dimension of input vector\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "def norm_human36m(X):\n",
    "    num_sample = X.shape[0]\n",
    "    # Keypoints\n",
    "    Pelvis = X[:,index_human36m['Pelvis']*2:index_human36m['Pelvis']*2+2]\n",
    "    Head = X[:,index_human36m['Head']*2:index_human36m['Head']*2+2]\n",
    "    Thorax = X[:,index_human36m['Thorax']*2:index_human36m['Thorax']*2+2]\n",
    "    RShoulder = X[:,index_human36m['RShoulder']*2:index_human36m['RShoulder']*2+2]\n",
    "    RElbow = X[:,index_human36m['RElbow']*2:index_human36m['RElbow']*2+2]\n",
    "    RWrist = X[:,index_human36m['RWrist']*2:index_human36m['RWrist']*2+2]\n",
    "    LShoulder = X[:,index_human36m['LShoulder']*2:index_human36m['LShoulder']*2+2]\n",
    "    LElbow = X[:,index_human36m['LElbow']*2:index_human36m['LElbow']*2+2]\n",
    "    LWrist = X[:,index_human36m['LWrist']*2:index_human36m['LWrist']*2+2]\n",
    "    RHip = X[:,index_human36m['RHip']*2:index_human36m['RHip']*2+2]\n",
    "    RKnee = X[:,index_human36m['RKnee']*2:index_human36m['RKnee']*2+2]\n",
    "    RAnkle = X[:,index_human36m['RAnkle']*2:index_human36m['RAnkle']*2+2]\n",
    "    LHip = X[:,index_human36m['LHip']*2:index_human36m['LHip']*2+2]\n",
    "    LKnee = X[:,index_human36m['LKnee']*2:index_human36m['LKnee']*2+2]\n",
    "    LAnkle = X[:,index_human36m['LAnkle']*2:index_human36m['LAnkle']*2+2]\n",
    "\n",
    "\n",
    "    # Length of head\n",
    "    length_Head_Thorax = euclidean_dist(Head, Thorax)\n",
    "    length_head      = np.maximum.reduce([length_Head_Thorax])\n",
    "\n",
    "    # Length of torso\n",
    "    length_Thorax_LHip = euclidean_dist(Thorax, LHip)\n",
    "    length_Thorax_RHip = euclidean_dist(Thorax, RHip)\n",
    "    length_torso     = np.maximum(length_Thorax_LHip, length_Thorax_RHip)\n",
    "\n",
    "    # Length of right leg\n",
    "    length_leg_right = euclidean_dist(RHip, RKnee) + euclidean_dist(RKnee, RAnkle)\n",
    "  \n",
    "    # Length of left leg\n",
    "    length_leg_left = euclidean_dist(LHip, LKnee) + euclidean_dist(LKnee, LAnkle)\n",
    "\n",
    "\n",
    "    # Length of leg\n",
    "    length_leg = np.maximum(length_leg_right, length_leg_left)\n",
    "\n",
    "    # Length of body\n",
    "    length_body = length_head + length_torso + length_leg\n",
    "    \n",
    "    # Check all samples have length_body of 0\n",
    "    length_chk = (length_body > 0).astype(int)\n",
    "    \n",
    "    # Check keypoints at origin\n",
    "    keypoints_chk = (X > 0).astype(int)\n",
    "    \n",
    "    chk = length_chk * keypoints_chk\n",
    "    \n",
    "    # Set all length_body of 0 to 1 (to avoid division by 0)\n",
    "    length_body[length_body == 0] = 1\n",
    "    \n",
    "    # The center of gravity\n",
    "    num_pts = (X[:, 0::2] > 0).sum(1).reshape(num_sample,1)\n",
    "\n",
    "    centr_x = X[:, 0::2].sum(1).reshape(num_sample,1) / num_pts\n",
    "    centr_y = X[:, 1::2].sum(1).reshape(num_sample,1) / num_pts\n",
    "\n",
    "    # The  coordinates  are  normalized relative to the length of the body and the center of gravity\n",
    "    X_norm_x = (X[:, 0::2] - centr_x) / length_body\n",
    "    X_norm_y = (X[:, 1::2] - centr_y) / length_body\n",
    "    \n",
    "    # Stack 1st element x and y together\n",
    "    X_norm = np.column_stack((X_norm_x[:,:1], X_norm_y[:,:1]))\n",
    "        \n",
    "    for i in range(1, X.shape[1]//2):\n",
    "        X_norm = np.column_stack((X_norm, X_norm_x[:,i:i+1], X_norm_y[:,i:i+1]))\n",
    "    \n",
    "    # Set all samples have length_body of 0 to origin (0, 0)\n",
    "    X_norm = X_norm * chk\n",
    "    \n",
    "    return X_norm\n",
    "\n",
    "def euclidean_dist_3D(a, b):\n",
    "\n",
    "    try:\n",
    "        if (a.shape[1] == 3 and a.shape == b.shape):\n",
    "            # check if element of a and b is (0,0)\n",
    "            bol_a = (a[:,0] != 0).astype(int)\n",
    "            bol_b = (b[:,0] != 0).astype(int)\n",
    "            dist = np.linalg.norm(a-b, axis=1)\n",
    "            return((dist*bol_a*bol_b).reshape(a.shape[0],1))\n",
    "    except:\n",
    "        print(\"[Error]: Check dimension of input vector\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "def norm_human36m_3D(X):\n",
    "    num_sample = X.shape[0]\n",
    "    # Keypoints\n",
    "    Pelvis = X[:,index_human36m['Pelvis']*3:index_human36m['Pelvis']*3+3]\n",
    "    Head = X[:,index_human36m['Head']*3:index_human36m['Head']*3+3]\n",
    "    Thorax = X[:,index_human36m['Thorax']*3:index_human36m['Thorax']*3+3]\n",
    "    RShoulder = X[:,index_human36m['RShoulder']*3:index_human36m['RShoulder']*3+3]\n",
    "    RElbow = X[:,index_human36m['RElbow']*3:index_human36m['RElbow']*3+3]\n",
    "    RWrist = X[:,index_human36m['RWrist']*3:index_human36m['RWrist']*3+3]\n",
    "    LShoulder = X[:,index_human36m['LShoulder']*3:index_human36m['LShoulder']*3+3]\n",
    "    LElbow = X[:,index_human36m['LElbow']*3:index_human36m['LElbow']*3+3]\n",
    "    LWrist = X[:,index_human36m['LWrist']*3:index_human36m['LWrist']*3+3]\n",
    "    RHip = X[:,index_human36m['RHip']*3:index_human36m['RHip']*3+3]\n",
    "    RKnee = X[:,index_human36m['RKnee']*3:index_human36m['RKnee']*3+3]\n",
    "    RAnkle = X[:,index_human36m['RAnkle']*3:index_human36m['RAnkle']*3+3]\n",
    "    LHip = X[:,index_human36m['LHip']*3:index_human36m['LHip']*3+3]\n",
    "    LKnee = X[:,index_human36m['LKnee']*3:index_human36m['LKnee']*3+3]\n",
    "    LAnkle = X[:,index_human36m['LAnkle']*3:index_human36m['LAnkle']*3+3]\n",
    "\n",
    "\n",
    "    # Length of head\n",
    "    length_Head_Thorax = euclidean_dist_3D(Head, Thorax)\n",
    "    length_head      = np.maximum.reduce([length_Head_Thorax])\n",
    "\n",
    "    # Length of torso\n",
    "    length_Thorax_LHip = euclidean_dist_3D(Thorax, LHip)\n",
    "    length_Thorax_RHip = euclidean_dist_3D(Thorax, RHip)\n",
    "    length_torso     = np.maximum(length_Thorax_LHip, length_Thorax_RHip)\n",
    "\n",
    "    # Length of right leg\n",
    "    length_leg_right = euclidean_dist_3D(RHip, RKnee) + euclidean_dist_3D(RKnee, RAnkle)\n",
    "  \n",
    "    # Length of left leg\n",
    "    length_leg_left = euclidean_dist_3D(LHip, LKnee) + euclidean_dist_3D(LKnee, LAnkle)\n",
    "\n",
    "\n",
    "    # Length of leg\n",
    "    length_leg = np.maximum(length_leg_right, length_leg_left)\n",
    "\n",
    "    # Length of body\n",
    "    length_body = length_head + length_torso + length_leg\n",
    "    \n",
    "    # Check all samples have length_body of 0\n",
    "    length_chk = (length_body > 0).astype(int)\n",
    "    \n",
    "    # Check keypoints at origin\n",
    "    keypoints_chk = (X > 0).astype(int)\n",
    "    \n",
    "    chk = length_chk * keypoints_chk\n",
    "    \n",
    "    # Set all length_body of 0 to 1 (to avoid division by 0)\n",
    "    length_body[length_body == 0] = 1\n",
    "    \n",
    "    # The center of gravity\n",
    "    num_pts = np.full((num_sample, 1), 32)\n",
    "    print(num_pts)\n",
    "    centr_x = X[:, 0::3].sum(1).reshape(num_sample,1) / num_pts\n",
    "    centr_y = X[:, 1::3].sum(1).reshape(num_sample,1) / num_pts\n",
    "    centr_z = X[:, 2::3].sum(1).reshape(num_sample,1) / num_pts\n",
    "\n",
    "    # The  coordinates  are  normalized relative to the length of the body and the center of gravity\n",
    "    X_norm_x = (X[:, 0::3] - centr_x) / length_body\n",
    "    X_norm_y = (X[:, 1::3] - centr_y) / length_body\n",
    "    X_norm_z = (X[:, 2::3] - centr_z) / length_body\n",
    "\n",
    "    # Stack 1st element x and y together\n",
    "    X_norm = np.column_stack((X_norm_x[:,:1], X_norm_y[:,:1], X_norm_z[:,:1]))\n",
    "        \n",
    "    for i in range(1, X.shape[1]//3):\n",
    "        X_norm = np.column_stack((X_norm, X_norm_x[:,i:i+1], X_norm_y[:,i:i+1], X_norm_z[:,i:i+1]))\n",
    "    \n",
    "    # Set all samples have length_body of 0 to origin (0, 0)\n",
    "    X_norm = X_norm * chk\n",
    "    \n",
    "    return X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74175244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "normalized_eucledianhuman36m=norm_human36m(skeleton2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6288fa75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7111, 64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_eucledianhuman36m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e906372",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path='../inference_result_npy/'+base+'_2D_Proscrutes_Normalized.json'\n",
    "save_to_json_2D(normalized_eucledianhuman36m, path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3650cbc9",
   "metadata": {},
   "source": [
    "# Inference Code (Convert only 1 Skeleton)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5c32b4",
   "metadata": {},
   "source": [
    "## 2D to 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6a2b0a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferencealphaposeto3d_one(alpha2d, input_type=\"json\"):\n",
    "    converted = []\n",
    "    # human2d=alpha2d.copy()\n",
    "    # human3d=alpha2d.copy()\n",
    "\n",
    "    if (input_type == \"json\"):\n",
    "        convert = np.asarray(data_converter(alpha2d))\n",
    "    else:\n",
    "        convert = alpha2d\n",
    "\n",
    "    a = dim_to_use_2d.tolist()\n",
    "    a.insert(18, 28)\n",
    "    a.insert(19, 29)\n",
    "    dim_to_use_2d_nose = np.asarray(a)\n",
    "\n",
    "    human36m_output = map_alpha_to_human_classification(convert)\n",
    "    human36m_output = human36m_output.astype('float')\n",
    "    human2d = human36m_output[dim_to_use_2d_nose]\n",
    "\n",
    "    human36m_alpha_example = map_alpha_to_human(convert)\n",
    "    normalized = normalize_single_data(human36m_alpha_example, data_mean_2d, data_std_2d, dim_to_use_2d)\n",
    "    normalized = normalized.astype('float')\n",
    "    converted.append(normalized)\n",
    "    converted = np.asarray(converted)\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        dataset=Human36M_testing(converted, True),\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True)\n",
    "\n",
    "    #Doing Inference\n",
    "    pred_result_all=test(test_loader, model, criterion, new_stat_3d) #All\n",
    "    dim_use = np.hstack((np.arange(3), dim_to_use_3d))\n",
    "    prediction=pred_result_all[0][0][dim_use]\n",
    "    centroids = find_centroid_single(prediction)\n",
    "    angles = [0, 0, 260]\n",
    "    human3d = rotate_single(centroids, prediction, angles)\n",
    "    \n",
    "    human3d=human3d-np.tile(human3d[:3],[17])\n",
    "\n",
    "    return human3d, human2d\n",
    "\n",
    "def mapalphaposetohuman_one(alpha2d,input_type=\"json\"):\n",
    "    \n",
    "    # Input type should be in json format\n",
    "    if (input_type==\"json\"):\n",
    "        convert=np.asarray(data_converter(alpha2d))\n",
    "        skeletonhuman=alpha2d.copy()\n",
    "        \n",
    "    # Input type should be in array has shape (34,)\n",
    "    elif (input_type==\"array\"):\n",
    "        convert=alpha2d\n",
    "     \n",
    "    a=dim_to_use_2d.tolist()\n",
    "    a.insert(18,28)\n",
    "    a.insert(19,29)\n",
    "    dim_to_use_2d_nose=np.asarray(a)\n",
    "    \n",
    "    human36m_alpha=map_alpha_to_human_classification(convert)\n",
    "    human36m_alpha=human36m_alpha.astype('float')\n",
    "\n",
    "    if (input_type==\"json\"):\n",
    "        skeletonhuman['keypoints']=human36m_alpha[dim_to_use_2d_nose].tolist()\n",
    "    elif (input_type==\"array\"):\n",
    "        skeletonhuman=human36m_alpha[dim_to_use_2d_nose]\n",
    "        \n",
    "    return skeletonhuman\n",
    "        \n",
    "\n",
    "      \n",
    "def find_centroid_single(skeletons):\n",
    "    skeleton_test=skeletons.reshape(int(51/3),3)\n",
    "    centroid=np.mean(skeleton_test, axis=0)\n",
    "    return centroid\n",
    "\n",
    "def rotate_single(origin, skeletons, angle):\n",
    "    \"\"\"\n",
    "    Rotate a point counterclockwise by a given angle around a given origin.\n",
    "\n",
    "    The angle should be given in radians.\n",
    "    \"\"\"\n",
    "    joints = []\n",
    "    skeleton_test=skeletons.reshape(int(51/3),3)\n",
    "    angle_xy,angle_xz,angle_yz=math.radians(angle[0]),math.radians(angle[1]),math.radians(angle[2])\n",
    "\n",
    "    for j,join in enumerate(skeleton_test):\n",
    "        ox, oy,oz = origin[0],origin[1],origin[2]\n",
    "        px, py,pz = join[0],join[1],join[2]\n",
    "\n",
    "        #Rotation XY\n",
    "        qx = ox + math.cos(angle_xy) * (px - ox) - math.sin(angle_xy) * (py - oy)\n",
    "        qy = oy + math.sin(angle_xy) * (px - ox) + math.cos(angle_xy) * (py - oy)\n",
    "        px, py,pz=qx,qy,pz\n",
    "\n",
    "        #Rotation XZ\n",
    "        qx = ox + math.cos(angle_xz) * (px - ox) - math.sin(angle_xz) * (pz - oz)\n",
    "        qz = oz + math.sin(angle_xz) * (px - ox) + math.cos(angle_xz) * (pz - oz)\n",
    "        px, py,pz=qx,py,qz\n",
    "\n",
    "        #Rotation YZ\n",
    "        qy = oy + math.cos(angle_yz) * (py - oy) - math.sin(angle_yz) * (pz - oz)\n",
    "        qz = oz + math.sin(angle_yz) * (py - oy) + math.cos(angle_yz) * (pz - oz)\n",
    "        px, py,pz=px,qy,qz\n",
    "\n",
    "        joints.append(px)\n",
    "        joints.append(py)\n",
    "        joints.append(pz)\n",
    "\n",
    "    rotated=np.asarray(joints)\n",
    "    return rotated  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "48f3c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../json_test/taoyuan_angle2.json'\n",
    "f = open(path) \n",
    "data = json.load(f) \n",
    "# input_to=np.asarray(data_converter(data[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "84fdc6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 48])\n"
     ]
    }
   ],
   "source": [
    "# How to use function\n",
    "# output_3d=inferencealphaposeto3d_one(data[0])\n",
    "# output_2d=mapalphaposetohuman_one(data[0])\n",
    "\n",
    "pose2d_size = 34\n",
    "pose3d_size= 51    \n",
    "_pose =data_converter(data[0])\n",
    "_pose=np.asarray(_pose).reshape(pose2d_size,)\n",
    "human3d,human2d = inferencealphaposeto3d_one(_pose, input_type=\"array\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "85c6d101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.        ,    0.        ,    0.        ,  -97.96893723,\n",
       "          4.89787565,    3.95191025,  -34.01093909, -166.221619  ,\n",
       "       -243.54173464,  -71.7219329 , -229.46961206, -680.35125224,\n",
       "         98.43087331,   -6.39361148,   -2.97029149,  110.67299713,\n",
       "       -189.21741016, -282.61039279,  135.27674833, -263.75053657,\n",
       "       -726.96221609,  -14.73443061,   31.10116506,  221.49901354,\n",
       "        -42.40683965,   33.57538791,  476.3319972 , -127.23909158,\n",
       "        -57.47653559,  450.27545064,  -92.76190021,  -48.04986756,\n",
       "        480.31859219,  144.83576516,   -5.86608964,  474.54021261,\n",
       "        257.14100665,  -73.16804019,  295.78095093,  232.47327325,\n",
       "        -99.07206838,  106.50369086, -201.82564679,   47.53198948,\n",
       "        474.05071025, -255.80565837,  163.81497169,  345.51985076,\n",
       "       -308.65474031,   94.64010333,  232.74232922])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output is array of 3D Pose baseline with shape (51,)\n",
    "human3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1b0bb9",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b05c85d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_path='../inference_result_npy/taoyuan_angle2_3D_Original to taoyuan_angle1_3D_Original_transformationvalue.pickle'\n",
    "\n",
    "with open(trans_path, 'rb') as fp:\n",
    "    trans = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "87c3bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map3dto2dcamera_single( poses_set, cams, ncams=4 ):\n",
    "    \"\"\"\n",
    "    Project 3d poses using camera parameters\n",
    "\n",
    "    cams: dictionary with camera parameters\n",
    "    ncams: number of cameras per subject\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    for cam in range( ncams ):\n",
    "        R, T, f, c, k, p, name = cams[ (11, cam+1) ]\n",
    "        pts2d, _, _, _, _ = project_point_radial( np.reshape(poses_set, [-1, 3]), R, T, f, c, k, p )\n",
    "\n",
    "        pts2d = np.reshape( pts2d, [17*2] )\n",
    "\n",
    "    return pts2d\n",
    "\n",
    "\n",
    "def find_transformation_single(trans,skeleton3d):\n",
    "    \n",
    "    T=trans['T']\n",
    "    b=trans['b']\n",
    "    c=trans['c']\n",
    "    \n",
    "    skeleton3d = skeleton3d.reshape(-1, 3)\n",
    "    skeleton3d = (b * skeleton3d.dot(T)) + c\n",
    "    skeleton3d=skeleton3d.reshape(51,)\n",
    "    \n",
    "    #Recenter the skeleton and put hip to coordinate 0,0,0\n",
    "    poses3d=skeleton3d-np.tile(skeleton3d[:3],[17])\n",
    "    poses2d=map3dto2dcamera_single(poses3d,rcams,4)\n",
    "    \n",
    "    return  poses3d,poses2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "87f217dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "human3d_trans,human2d_trans=find_transformation_single(trans,human3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "593635f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human3d_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "db1aa4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human2d_trans.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8462321",
   "metadata": {},
   "source": [
    "# Dataset Augmentation using 3D Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15f75946",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def combine_allTransform(path):\n",
    "    trans_file=sorted(glob.glob(path+\"/*.pickle\"))\n",
    "    all_transf={}\n",
    "    index=0\n",
    "    for file in trans_file:\n",
    "        with open(file, 'rb') as f:\n",
    "            transformation_value = pickle.load(f)\n",
    "        all_transf[index]=transformation_value\n",
    "        index=index+1\n",
    "    return all_transf\n",
    "\n",
    "def augment_usingtransvalue(transvalue,skeleton_b):\n",
    "     # remove dim ignored\n",
    "    dim_use = np.hstack((np.arange(3), new_stat_3d['dim_use']))\n",
    "\n",
    "\n",
    "    new_transformed=[]\n",
    "    index_=0\n",
    "    new_transformed.append(skeleton_b.reshape(-1, 3))\n",
    "    for key in transvalue:\n",
    "        transformation_value=transvalue[key]\n",
    "        T = transformation_value['T']\n",
    "        b = transformation_value['b']\n",
    "        c = transformation_value['c']\n",
    "\n",
    "        skeleton_b = skeleton_b.reshape(-1, 3)\n",
    "        transformed = (b * skeleton_b.dot(T)) + c\n",
    "        transformed = skeleton_b.dot(T)\n",
    "        new_transformed.append(transformed)\n",
    "        index_=index_+1\n",
    "        \n",
    "            \n",
    "    try:\n",
    "        skeleton3D=np.asarray(new_transformed)\n",
    "        skeleton3D=skeleton3D.reshape(skeleton3D.shape[0],96)\n",
    "        #Recenter the hip after transformation\n",
    "        poses=skeleton3D-np.tile(skeleton3D[:,:3],[1,32])\n",
    "    except:\n",
    "        skeleton3D=np.asarray(new_transformed)\n",
    "        skeleton3D=skeleton3D.reshape(skeleton3D.shape[0],51)\n",
    "        #Recenter the hip after transformation\n",
    "        poses=skeleton3D-np.tile(skeleton3D[:,:3],[1,17])\n",
    "\n",
    "    return  poses\n",
    "\n",
    "def augment_jsonfile(json_path,transf_folder_path):\n",
    "    all_transf=combine_allTransform(transf_folder_path)\n",
    "    \n",
    "    with open(json_path, 'rb') as f:\n",
    "        angle1 = json.load(f)\n",
    "        \n",
    "    new_augmented=[]\n",
    "    for skeleton in angle1:\n",
    "        tmp_dict=skeleton.copy()\n",
    "        augmented=augment_usingtransvalue(all_transf,np.asarray(skeleton['keypoints']).reshape(1,51))\n",
    "        for augmented_skeleton in augmented:\n",
    "            tmp_dict['keypoints']=augmented_skeleton.tolist()\n",
    "            new_augmented.append(tmp_dict)\n",
    "            \n",
    "    \n",
    "    return new_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d67ffbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path='../inference_result_npy/taoyuan_angle1_3D_Original.json'\n",
    "transf_folder_path=\"../augmented_transformation\"\n",
    "\n",
    "new_augmented=augment_jsonfile(json_path,transf_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9cf24601",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename= os.path.splitext(os.path.basename(json_path))[0]+\"_augmented.json\"\n",
    "json_path_augmented=os.path.dirname(json_path)+\"/\"+filename\n",
    "\n",
    "with open(json_path_augmented, 'w') as fp:\n",
    "    fp.write(json.dumps(new_augmented))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaa9ebf",
   "metadata": {},
   "source": [
    "# Don't run (just experiment and random code) !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186e469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_class=set([])\n",
    "for a in new:\n",
    "    unique_class.add(a['pose_class'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f6a7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4696d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open(\"../../../Falling Dataset/Thesis Experiment/data/taoyuan.json\") \n",
    "\n",
    "# returns JSON object as  \n",
    "# a dictionary \n",
    "data = json.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8986ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "taoyuan_angle1=[]\n",
    "taoyuan_angle2=[]\n",
    "\n",
    "for a in data:\n",
    "    if ((a['pose_class']==\"FallingDown_01\") or (a['pose_class']==\"Standing_01\")):\n",
    "        taoyuan_angle1.append(a)\n",
    "    else:\n",
    "        taoyuan_angle2.append(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bcb474",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../Falling Dataset/Thesis Experiment/data/taoyuan_angle1.json\", 'w') as fp:\n",
    "    fp.write(json.dumps(taoyuan_angle1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72956fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../Falling Dataset/Thesis Experiment/data/taoyuan_angle2.json\", 'w') as fp:\n",
    "    fp.write(json.dumps(taoyuan_angle2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
