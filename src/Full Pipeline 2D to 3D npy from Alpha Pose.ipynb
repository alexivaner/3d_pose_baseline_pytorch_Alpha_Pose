{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "about-spine",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import cameras\n",
    "import data_utils\n",
    "import linear_model\n",
    "import procrustes\n",
    "import viz\n",
    "import glob\n",
    "import cdflib\n",
    "sys.argv = sys.argv[:1]\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import data_process as data_process\n",
    "\n",
    "import json \n",
    "from model import LinearModel, weight_init\n",
    "import torch.nn as nn\n",
    "import utils as utils\n",
    "\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname('__file__'), \"progress\"))\n",
    "\n",
    "from progress.bar import Bar as Bar\n",
    "\n",
    "# Load Human3.6M Skeleton\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pickle\n",
    "\n",
    "tf.app.flags.DEFINE_string(\"action\",\"All\", \"The action to train on. 'All' means all the actions\")\n",
    "\n",
    "# Directories\n",
    "tf.app.flags.DEFINE_string(\"cameras_path\",\"../data/h36m/metadata.xml\", \"File with h36m metadata, including cameras\")\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-telephone",
   "metadata": {},
   "source": [
    "# Initiate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "occasional-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECT_IDS = [1,5,6,7,8,9,11]\n",
    "this_file = os.path.dirname(os.path.realpath('__file__'))\n",
    "\n",
    "#Load metadata.xml camera\n",
    "rcams = cameras.load_cameras(os.path.join(this_file, FLAGS.cameras_path), SUBJECT_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "detailed-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Joints in H3.6M -- data has 32 joints, but only 17 that move; these are the indices.\n",
    "H36M_NAMES = ['']*32\n",
    "H36M_NAMES[0]  = 'Hip'\n",
    "H36M_NAMES[1]  = 'RHip'\n",
    "H36M_NAMES[2]  = 'RKnee'\n",
    "H36M_NAMES[3]  = 'RFoot'\n",
    "H36M_NAMES[6]  = 'LHip'\n",
    "H36M_NAMES[7]  = 'LKnee'\n",
    "H36M_NAMES[8]  = 'LFoot'\n",
    "H36M_NAMES[12] = 'Spine'\n",
    "H36M_NAMES[13] = 'Thorax'\n",
    "H36M_NAMES[14] = 'Neck/Nose'\n",
    "H36M_NAMES[15] = 'Head'\n",
    "H36M_NAMES[17] = 'LShoulder'\n",
    "H36M_NAMES[18] = 'LElbow'\n",
    "H36M_NAMES[19] = 'LWrist'\n",
    "H36M_NAMES[25] = 'RShoulder'\n",
    "H36M_NAMES[26] = 'RElbow'\n",
    "H36M_NAMES[27] = 'RWrist'\n",
    "\n",
    "index_alphapose={\n",
    "    # Use 17 skeleton point\n",
    "    \"Nose\": 0,\n",
    "    \"RShoulder\": 6,\n",
    "    \"RElbow\": 8,\n",
    "    \"RWrist\": 10,\n",
    "    \"LShoulder\": 5,\n",
    "    \"LElbow\": 7,\n",
    "    \"LWrist\": 9,\n",
    "    \"RHip\": 12,\n",
    "    \"RKnee\": 14,\n",
    "    \"RAnkle\": 16,\n",
    "    \"LHip\": 11,\n",
    "    \"LKnee\": 13,\n",
    "    \"LAnkle\": 15,\n",
    "    \"REye\": 2,\n",
    "    \"LEye\": 1,\n",
    "    \"REar\": 4,\n",
    "    \"LEar\": 3\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "index_mapping={\n",
    "# Alpha Pose to Human 3.6M\n",
    "\"Hip\": [20, 0],\n",
    "\"RHip\": [12,1],\n",
    "\"RKnee\": [14,2],\n",
    "\"RFoot\": [16,3],\n",
    "\"LHip\": [11,6],\n",
    "\"LKnee\": [13,7],\n",
    "\"LFoot\": [15,8],\n",
    "\"Spine\": [19,12],\n",
    "\"Thorax\": [18,13],\n",
    "\"Head\": [17,15],\n",
    "\"LShoulder\": [5,17],\n",
    "\"LElbow\": [7,18],\n",
    "\"LWrist\": [9,19],\n",
    "\"RShoulder\": [6,25],\n",
    "\"RElbow\": [8,26],\n",
    "\"RWrist\": [10,27]\n",
    "}\n",
    "\n",
    "\n",
    "def data_converter(data):\n",
    "    data=data['keypoints']\n",
    "    keypoints=[]\n",
    "    kp_score=[]\n",
    "    for a in range (0,len(data)):\n",
    "        score=[]\n",
    "        if ((a+3)%3==0):\n",
    "            keypoints.append(data[a])\n",
    "            keypoints.append(data[a+1])\n",
    "        elif((a+1)%3==0):\n",
    "            score=data[a]\n",
    "            kp_score.append(score)\n",
    "\n",
    "    return keypoints\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eleven-sunrise",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def count_head(alpha_pose):\n",
    "    x = (alpha_pose[index_alphapose['LEar']*2]+alpha_pose[index_alphapose['REar']*2])/2\n",
    "    y = (alpha_pose[index_alphapose['LEar']*2+1]+alpha_pose[index_alphapose['REar']*2+1])/2\n",
    "    return x,y\n",
    "\n",
    "\n",
    "def count_thorax(alpha_pose):\n",
    "    x = (alpha_pose[index_alphapose['LShoulder']*2]+alpha_pose[index_alphapose['RShoulder']*2])/2\n",
    "    y = (alpha_pose[index_alphapose['LShoulder']*2+1]+alpha_pose[index_alphapose['RShoulder']*2+1])/2\n",
    "    return x,y\n",
    "\n",
    "\n",
    "def count_spine(alpha_pose):\n",
    "    hip_x,hip_y=count_hip(alpha_pose)\n",
    "    thorax_x,thorax_y=count_thorax(alpha_pose)\n",
    "    x = (hip_x+thorax_x)/2\n",
    "    y = (hip_y+thorax_y)/2\n",
    "    return x,y\n",
    "\n",
    "def count_hip(alpha_pose):\n",
    "    x = (alpha_pose[index_alphapose['LHip']*2]+alpha_pose[index_alphapose['RHip']*2])/2\n",
    "    y = (alpha_pose[index_alphapose['LHip']*2+1]+alpha_pose[index_alphapose['RHip']*2+1])/2\n",
    "    return x,y\n",
    "\n",
    "def add_features(alpha_pose):\n",
    "    #Count Head\n",
    "    head_x,head_y=count_head(alpha_pose)\n",
    "    alpha_pose=np.append(alpha_pose,(head_x,head_y))\n",
    "    \n",
    "    #Count Thorax\n",
    "    thorax_x,thorax_y=count_thorax(alpha_pose)\n",
    "    alpha_pose=np.append(alpha_pose,(thorax_x,thorax_y))\n",
    " \n",
    "    \n",
    "    #Count Spine\n",
    "    spine_x,spine_y=count_spine(alpha_pose)\n",
    "    alpha_pose=np.append(alpha_pose,(spine_x,spine_y))\n",
    "    \n",
    "    #Count Hip\n",
    "    hip_x,hip_y=count_hip(alpha_pose)\n",
    "    alpha_pose=np.append(alpha_pose,(hip_x,hip_y))\n",
    "    \n",
    "    return alpha_pose\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "perceived-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_alpha_to_human(alpha_pose):\n",
    "    alpha_pose=add_features(alpha_pose)\n",
    "    temp_list = [None] * 64\n",
    "    for a,b in index_mapping.items():\n",
    "        temp_list[b[1]*2]=alpha_pose[b[0]*2]\n",
    "        temp_list[b[1]*2+1]=alpha_pose[b[0]*2+1]\n",
    "    human36m=np.asarray(temp_list)\n",
    "    return human36m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-mouth",
   "metadata": {},
   "source": [
    "# Do 3D Prediction from Custom Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-spectacular",
   "metadata": {},
   "source": [
    "## Using Created Statistic Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "interested-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize=True\n",
    "actions = data_utils.define_actions( FLAGS.action )\n",
    "# Human3.6m IDs for training and testing\n",
    "TRAIN_SUBJECTS = [1,5,6,7,8]\n",
    "TEST_SUBJECTS  = [9,11]\n",
    "\n",
    "\n",
    "stat_3D = torch.load('../data/stat_3d.pth.tar')\n",
    "stat_2D = torch.load('../data/stat_2d.pth.tar')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unique-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_mean_2d, data_std_2d, dim_to_ignore_2d, dim_to_use_2d = stat_2D['mean'],stat_2D['std'],stat_2D['dim_ignore'],stat_2D['dim_use']\n",
    "data_mean_3d, data_std_3d, dim_to_ignore_3d, dim_to_use_3d = stat_3D['mean'],stat_3D['std'],stat_3D['dim_ignore'],stat_3D['dim_use']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "younger-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the json data\n",
    "#load json data using json,load(f)\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "class Human36M_testing(Dataset):\n",
    "    def __init__(self, skeleton,many=False):\n",
    "        \"\"\"\n",
    "        :param actions: list of actions to use\n",
    "        :param data_path: path to dataset\n",
    "        :param use_hg: use stacked hourglass detections\n",
    "        :param is_train: load train/test dataset\n",
    "        \"\"\"\n",
    "\n",
    "        self.test_inp, self.test_out = [], []\n",
    "\n",
    "        # loading data\n",
    "        # load test data\n",
    "       \n",
    "        if many:\n",
    "            num_f= skeleton.shape\n",
    "            for i in range(num_f[0]):\n",
    "                self.test_inp.append(skeleton[i])\n",
    "        else:\n",
    "            self.test_inp.append(skeleton)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        inputs = torch.from_numpy(self.test_inp[index]).float()\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.test_inp)\n",
    "    \n",
    "def normalize_single_data(data, data_mean, data_std, dim_to_use ):\n",
    "    \"\"\"Normalizes a dictionary of poses\n",
    "\n",
    "    Args\n",
    "    data: dictionary where values are\n",
    "    data_mean: np vector with the mean of the data\n",
    "    data_std: np vector with the standard deviation of the data\n",
    "    dim_to_use: list of dimensions to keep in the data\n",
    "    Returns\n",
    "    data_out: dictionary with same keys as data, but values have been normalized\n",
    "    \"\"\"\n",
    "\n",
    "    data= data[dim_to_use]\n",
    "    mu = data_mean[dim_to_use]\n",
    "    stddev = data_std[dim_to_use]\n",
    "    data_out= np.divide( (data - mu), stddev )\n",
    "\n",
    "    return data_out\n",
    "def create_datatest(data):\n",
    "    converted=[]\n",
    "    for dat in data:\n",
    "        convert=np.asarray(data_converter(dat))\n",
    "        human36m_alpha_example=map_alpha_to_human(convert)\n",
    "        normalized=normalize_single_data(human36m_alpha_example,data_mean_2d,data_std_2d,dim_to_use_2d)\n",
    "        normalized=normalized.astype('float')\n",
    "        converted.append(normalized)\n",
    "\n",
    "    converted=np.asarray(converted) \n",
    "    test_loader = DataLoader(\n",
    "        dataset=Human36M_testing(converted,True),\n",
    "        batch_size=1024,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True)\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "southwest-advice",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acknowledged-gregory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> creating model\n",
      ">>> total params: 4.29M\n",
      ">>> loading ckpt from '../../3d_pose_baseline_pytorch/checkpoint/test/ckpt_best.pth.tar'\n",
      ">>> ckpt loaded (epoch: 147 | err: 42.151899649376176)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Project Lab\\THESIS_FALL_DETECTION\\2D to 3D Pose\\3d_pose_baseline_pytorch\\src\\model.py:11: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight)\n",
      "C:\\Users\\hutom\\anaconda3\\envs\\3DPose\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_path='../../3d_pose_baseline_pytorch/checkpoint/test/ckpt_best.pth.tar'\n",
    "# create model\n",
    "print(\">>> creating model\")\n",
    "model = LinearModel()\n",
    "model = model.cuda()\n",
    "model.apply(weight_init)\n",
    "print(\">>> total params: {:.2f}M\".format(sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "criterion = nn.MSELoss(size_average=True).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-3)\n",
    "\n",
    "print(\">>> loading ckpt from '{}'\".format('../../3d_pose_baseline_pytorch/checkpoint/test/ckpt_best.pth.tar'))\n",
    "ckpt = torch.load(model_path)\n",
    "start_epoch = ckpt['epoch']\n",
    "err_best = ckpt['err']\n",
    "glob_step = ckpt['step']\n",
    "lr_now = ckpt['lr']\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "optimizer.load_state_dict(ckpt['optimizer'])\n",
    "print(\">>> ckpt loaded (epoch: {} | err: {})\".format(start_epoch, err_best))\n",
    "\n",
    "new_stat_3d={}\n",
    "new_stat_3d['mean']=data_mean_3d\n",
    "new_stat_3d['std']=data_std_3d\n",
    "new_stat_3d['dim_use']=dim_to_use_3d\n",
    "new_stat_3d['dim_ignore']=dim_to_ignore_3d\n",
    "    \n",
    "def test(test_loader, model, criterion, stat_3d, procrustes=False):\n",
    "    losses = utils.AverageMeter()\n",
    "    model.eval()\n",
    "\n",
    "    all_dist = []\n",
    "    pred_result=[]\n",
    "    start = time.time()\n",
    "    batch_time = 0\n",
    "    bar = Bar('>>>', fill='>', max=len(test_loader))\n",
    "\n",
    "    for i, inps in enumerate(test_loader):\n",
    "        inputs = Variable(inps.cuda())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        # calculate erruracy\n",
    "        print(outputs.shape)\n",
    "        outputs_unnorm = data_process.unNormalizeData(outputs.data.cpu().numpy(), stat_3d['mean'], stat_3d['std'], stat_3d['dim_use'])\n",
    "\n",
    "        # remove dim ignored\n",
    "        dim_use = np.hstack((np.arange(3), stat_3d['dim_use']))\n",
    "\n",
    "        outputs_use = outputs_unnorm[:, dim_use]\n",
    "        pred_result.append(outputs_unnorm)\n",
    "        \n",
    "        # update summary\n",
    "        if (i + 1) % 100 == 0:\n",
    "            batch_time = time.time() - start\n",
    "            start = time.time()\n",
    "\n",
    "        bar.suffix = '({batch}/{size}) | batch: {batchtime:.4}ms | Total: {ttl} | ETA: {eta:} | loss: {loss:.6f}' \\\n",
    "            .format(batch=i + 1,\n",
    "                    size=len(test_loader),\n",
    "                    batchtime=batch_time * 10.0,\n",
    "                    ttl=bar.elapsed_td,\n",
    "                    eta=bar.eta_td,\n",
    "                    loss=losses.avg)\n",
    "        bar.next()\n",
    "    bar.finish()\n",
    "    return pred_result\n",
    "\n",
    "# Combine prediction from each batch into one prediction\n",
    "def combine_prediction(pred_result_all):\n",
    "    prediction_list = []\n",
    "    for pred in pred_result_all:\n",
    "        for pre in pred:\n",
    "            prediction_list.append(pre)\n",
    "    prediction_list=np.asarray(prediction_list)\n",
    "    return prediction_list\n",
    "\n",
    "\n",
    "def correct_3D(poses3d_input,poses2d_normalized):\n",
    "    _max = 0\n",
    "    _min = 10000\n",
    "    poses3d=np.copy(poses3d_input)\n",
    "    \n",
    "    spine_x = poses2d_normalized[0][24]\n",
    "    spine_y = poses2d_normalized[0][25]\n",
    "            \n",
    "    \n",
    "    for i in range(poses3d.shape[0]):\n",
    "\n",
    "        for j in range(32):\n",
    "\n",
    "            tmp = poses3d[i][j * 3 + 2]\n",
    "            poses3d[i][j * 3 + 2] = poses3d[i][j * 3 + 1]\n",
    "            poses3d[i][j * 3 + 1] = tmp\n",
    "            if poses3d[i][j * 3 + 2] > _max:\n",
    "                _max = poses3d[i][j * 3 + 2]\n",
    "                print(\"_max: \",_max)\n",
    "            if poses3d[i][j * 3 + 2] < _min:\n",
    "                _min = poses3d[i][j * 3 + 2]\n",
    "                print(\"_min: \",_min)\n",
    "\n",
    "    for i in range(poses3d.shape[0]):\n",
    "        for j in range(32):\n",
    "            poses3d[i][j * 3 + 2] = _max - poses3d[i][j * 3 + 2] + _min\n",
    "            poses3d[i][j * 3] += (spine_x - 630)\n",
    "            poses3d[i][j * 3 + 2] += (500 - spine_y)\n",
    "\n",
    "    return poses3d\n",
    "\n",
    "def inferencealphaposeto3D(path):\n",
    "    # Opening JSON file \n",
    "    f = open(path) \n",
    "\n",
    "    # returns JSON object as  \n",
    "    # a dictionary \n",
    "    data = json.load(f) \n",
    "\n",
    "\n",
    "    # Closing file \n",
    "    f.close() \n",
    "    all_test_data=create_datatest(data)\n",
    "    \n",
    "    pred_result_all=test(all_test_data, model, criterion, new_stat_3d) #All\n",
    "    \n",
    "    prediction_list=combine_prediction(pred_result_all)\n",
    "    \n",
    "    test_2d_normalized = np.asarray(all_test_data.dataset.test_inp) \n",
    "    fixed=correct_3D(prediction_list,test_2d_normalized)\n",
    "    \n",
    "    base=os.path.basename(path)\n",
    "    base=os.path.splitext(base)[0]\n",
    "    \n",
    "    with open('../inference_result_npy/'+base+'.npy', 'wb') as f:\n",
    "        np.save(f, fixed)\n",
    "    \n",
    "    return fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "foreign-remains",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 48])\n",
      "torch.Size([1024, 48])\n",
      "torch.Size([1024, 48])\n",
      "torch.Size([717, 48])\n",
      "_min:  0.0\n",
      "_max:  23.74018353833017\n",
      "_max:  380.1990142900833\n",
      "_max:  714.0541282291732\n",
      "_max:  742.1497253356404\n",
      "_min:  -23.740053932106353\n",
      "_max:  748.6368635545936\n",
      "_min:  -193.1940967258103\n",
      "_min:  -367.2188688863604\n",
      "_min:  -435.08890570553115\n",
      "_min:  -435.8228647302801\n",
      "_min:  -448.7604641562079\n",
      "_min:  -449.1551857555212\n",
      "_min:  -449.34476256537164\n",
      "_max:  749.7844913365291\n",
      "_max:  750.0728797480272\n",
      "_max:  750.0797652940556\n",
      "_max:  752.3011221701864\n",
      "_max:  753.9536894567138\n",
      "_max:  754.0561101419001\n",
      "_max:  754.0572770607534\n",
      "_max:  756.1461777751277\n",
      "_max:  756.2031031209244\n",
      "_max:  756.3576655094037\n",
      "_min:  -456.17790766677865\n",
      "_min:  -547.0309456177768\n",
      "_min:  -566.648016773134\n",
      "_min:  -591.0398371447454\n",
      "_min:  -623.1972695410624\n",
      "_min:  -636.5362085175566\n",
      "_min:  -637.8869959349664\n",
      "_min:  -639.1818992973043\n",
      "_min:  -640.3048061233621\n",
      "_min:  -642.1744767971251\n",
      "_min:  -642.8402653119958\n",
      "_min:  -642.8405109990489\n",
      "_max:  808.7606701582977\n",
      "_max:  851.6714299854415\n",
      "_max:  1066.7920485509237\n",
      "_max:  1100.1586688085035\n",
      "_min:  -657.1455855984741\n",
      "_min:  -739.2366217347713\n",
      "_min:  -1084.0838424478225\n"
     ]
    }
   ],
   "source": [
    "path='../json_test/AlphaPose_FallingDown_01_Angle 2.json'\n",
    "inference_result=inferencealphaposeto3D(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-operator",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
